{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import xgboost as xgb\n",
    "from lifelines import CoxPHFitter\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../examples/concordance_index.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I tried AFT XGBoost I tried the  following:\n",
    "1. Split the data into train and validation set\n",
    "2. Fitted the Cox PH regressor and evaluated it on the validation set with score of 0.0.6539783375777234;\n",
    "3. Used random forest classifier to predict efs, and added the predictions to the feature set;\n",
    "4. Obtained hyper parameters from an Optuna study;\n",
    "5. Performed unstratified 8-fold cross-validation and got the mean stratified C-score of 0.8860016472162744 (either data leakage or model is overfitting);\n",
    "6. Evaluated the model on the validation set and got the score of 0.6468318190816368. \n",
    "\n",
    "I didn't use any sophisticated preprocessing, just the simple imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data:\n",
    "\n",
    "data = pd.read_csv(\"../data/train_set.csv\")\n",
    "\n",
    "df_train_copy = data.copy(deep=True)\n",
    "\n",
    "# Categorical columns\n",
    "\n",
    "categ_columns = df_train_copy.select_dtypes(include = ['object']).columns\n",
    "\n",
    "to_replace = [\"Not done\", \"Not tested\", \"Other\", \"Missing disease status\", \"Non-resident of the U.S.\"]\n",
    "df_train_copy.loc[:,categ_columns] = df_train_copy[categ_columns].replace(to_replace, \"missing\")\n",
    "df_train_copy.loc[:,categ_columns] = df_train_copy[categ_columns].fillna('missing')\n",
    "\n",
    "# Numerical columns:\n",
    "\n",
    "num_columns = df_train_copy.select_dtypes(include = ['float64']).columns\n",
    "df_train_copy.loc[:, num_columns] = df_train_copy[num_columns].fillna(-1.0)\n",
    "target_features = ['efs', 'efs_time']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline:\n",
    "\n",
    "def create_preprocessor(categ_data, num_data):\n",
    "    \n",
    "    cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    num_imputer = SimpleImputer(strategy='mean')\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "        ('imputer', num_imputer),\n",
    "        ('scaler', scaler)\n",
    "    ])\n",
    "\n",
    "    cat_pipeline = Pipeline([\n",
    "        ('imputer', cat_imputer),\n",
    "        ('encoder', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat_imputer', cat_pipeline, categ_data),\n",
    "            ('num_imputer', num_pipeline, num_data)\n",
    "        ],\n",
    "        verbose_feature_names_out=False\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor)\n",
    "    ])\n",
    "    \n",
    "    return pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and validation sets \n",
    "\n",
    "df_train, df_val  = train_test_split(df_train_copy, test_size=0.2,random_state=42,stratify=df_train_copy['efs'])\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding both sets for Cox PH regressor:\n",
    "\n",
    "categ_data = df_train.select_dtypes(include='object').columns.tolist()\n",
    "num_data = df_train.drop([\"efs\", \"efs_time\",\"ID\"], axis=1).select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "processor = create_preprocessor(categ_data, num_data)\n",
    "X_train = processor.fit_transform(df_train)\n",
    "X_Val = processor.transform(df_val)\n",
    "feature_names = processor.named_steps['preprocessor'].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cox Proportional Hazard as a baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPH = CoxPHFitter()\n",
    "train_data = pd.DataFrame(X_train, columns = feature_names, index = df_train.index)\n",
    "train_plus = pd.concat([train_data, df_train[['efs', 'efs_time']]], axis =1)\n",
    "val_data = pd.DataFrame(X_Val, columns = feature_names, index = df_val.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPH.fit(train_plus, duration_col='efs_time', event_col='efs')\n",
    "predicted_hazards = CPH.predict_partial_hazard(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The stratified concordance score of Cox Proportional Hazard: 0.6539783375777234.\n"
     ]
    }
   ],
   "source": [
    "submissionCPH = pd.DataFrame({'ID': df_val[\"ID\"], 'prediction': predicted_hazards}) \n",
    "score_cph = score(df_val.copy(deep=True), submissionCPH.copy(deep=True), \"ID\")\n",
    "print(f\" The stratified concordance score of Cox Proportional Hazard: {score_cph}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Using the Random Forest Classifier to predict whether or not a row is censored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same preprocessed stuff\n",
    "\n",
    "y_train_forest = df_train['efs']\n",
    "\n",
    "y_val_forest = df_val['efs']\n",
    "RFC = RandomForestClassifier()\n",
    "RFC.fit(X_train,y_train_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18432,)\n",
      "9942.0\n"
     ]
    }
   ],
   "source": [
    "# Since by the below the training data has balanced labels, I can use accuracy as a metric\n",
    "\n",
    "print(y_train_forest.shape)\n",
    "print(y_train_forest.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Random Forest regressor on the validation set: 0.6742621527777778\n"
     ]
    }
   ],
   "source": [
    "y_pred = RFC.predict(X_Val)\n",
    "accuracy = accuracy_score(y_val_forest,y_pred)\n",
    "print(f\"The accuracy of the Random Forest regressor on the validation set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new column\n",
    "\n",
    "proba_column1 = RFC.predict_proba(X_train)[:, 1] \n",
    "df_train1 = df_train.copy(deep=True)\n",
    "df_train1[\"clf_proba\"] = proba_column1\n",
    "\n",
    "proba_column2 = RFC.predict_proba(X_Val)[:, 1]\n",
    "df_val1 = df_val.copy(deep=True)\n",
    "df_val1[\"clf_proba\"] = proba_column2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Optuna study to get hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-18 00:40:46,559] A new study created in memory with name: no-name-a7d39cca-795d-4d05-9689-63e7e772a383\n",
      "[I 2025-04-18 00:40:48,330] Trial 0 finished with value: 0.8658437595683127 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 2.9106359131330706, 'learning_rate': 0.030049873591901578, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.6232334448672797, 'colsample_bytree': 0.9464704583099741, 'lambda': 1.5930522616241016, 'alpha': 2.6070247583707675}. Best is trial 0 with value: 0.8658437595683127.\n",
      "[I 2025-04-18 00:40:50,047] Trial 1 finished with value: 0.8285386216616077 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 4.622589001020831, 'learning_rate': 0.009445600138094694, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.721696897183815, 'colsample_bytree': 0.8099025726528951, 'lambda': 0.7309539835912913, 'alpha': 0.38234752246751863}. Best is trial 0 with value: 0.8658437595683127.\n",
      "[I 2025-04-18 00:40:52,263] Trial 2 finished with value: 0.8632377030429083 and parameters: {'aft_loss_distribution': 'logistic', 'aft_loss_distribution_scale': 0.3839629299804172, 'learning_rate': 0.014983654548550792, 'max_depth': 6, 'min_child_weight': 8, 'subsample': 0.6798695128633439, 'colsample_bytree': 0.8056937753654446, 'lambda': 1.530485212183147, 'alpha': 0.1238513729886093}. Best is trial 0 with value: 0.8658437595683127.\n",
      "[I 2025-04-18 00:40:55,272] Trial 3 finished with value: 0.7819773485723956 and parameters: {'aft_loss_distribution': 'logistic', 'aft_loss_distribution_scale': 0.1349283426801325, 'learning_rate': 0.08580222514877409, 'max_depth': 10, 'min_child_weight': 9, 'subsample': 0.7218455076693483, 'colsample_bytree': 0.6390688456025535, 'lambda': 2.3359635026261603, 'alpha': 0.7591104805282695}. Best is trial 0 with value: 0.8658437595683127.\n",
      "[I 2025-04-18 00:40:57,321] Trial 4 finished with value: 0.8862736094554055 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.1171593739230706, 'learning_rate': 0.07621195864233186, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.7246844304357644, 'colsample_bytree': 0.8080272084711243, 'lambda': 1.2399967836846095, 'alpha': 0.23426581058204046}. Best is trial 4 with value: 0.8862736094554055.\n",
      "[I 2025-04-18 00:40:58,974] Trial 5 finished with value: 0.8093193449137949 and parameters: {'aft_loss_distribution': 'logistic', 'aft_loss_distribution_scale': 7.56829206016762, 'learning_rate': 0.07297384471483423, 'max_depth': 7, 'min_child_weight': 10, 'subsample': 0.6353970008207678, 'colsample_bytree': 0.678393144967658, 'lambda': 0.12315571723666023, 'alpha': 0.4473636174621265}. Best is trial 4 with value: 0.8862736094554055.\n",
      "[I 2025-04-18 00:41:00,521] Trial 6 finished with value: 0.8146080625621948 and parameters: {'aft_loss_distribution': 'logistic', 'aft_loss_distribution_scale': 4.544383960336017, 'learning_rate': 0.014558505116213708, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.6563696899899051, 'colsample_bytree': 0.9208787923016158, 'lambda': 0.14096175149815865, 'alpha': 9.41399304682995}. Best is trial 4 with value: 0.8862736094554055.\n",
      "[I 2025-04-18 00:41:03,091] Trial 7 finished with value: 0.7785317331871475 and parameters: {'aft_loss_distribution': 'logistic', 'aft_loss_distribution_scale': 0.1025756397418565, 'learning_rate': 0.057532041236250865, 'max_depth': 8, 'min_child_weight': 8, 'subsample': 0.9085081386743783, 'colsample_bytree': 0.6296178606936361, 'lambda': 0.5211124595788266, 'alpha': 0.17050539260269293}. Best is trial 4 with value: 0.8862736094554055.\n",
      "[I 2025-04-18 00:41:05,055] Trial 8 finished with value: 0.8714096292246726 and parameters: {'aft_loss_distribution': 'logistic', 'aft_loss_distribution_scale': 0.458982418149565, 'learning_rate': 0.006048689963516921, 'max_depth': 5, 'min_child_weight': 4, 'subsample': 0.8918424713352257, 'colsample_bytree': 0.8550229885420852, 'lambda': 5.948746813219774, 'alpha': 0.8798929749689021}. Best is trial 4 with value: 0.8862736094554055.\n",
      "[I 2025-04-18 00:41:07,692] Trial 9 finished with value: 0.8690668632386305 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 3.323304206226793, 'learning_rate': 0.026866338002255543, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.8090931317527976, 'colsample_bytree': 0.7710164073434198, 'lambda': 0.11241862095793062, 'alpha': 0.16435497475111327}. Best is trial 4 with value: 0.8862736094554055.\n",
      "[I 2025-04-18 00:41:09,357] Trial 10 finished with value: 0.8654164610639555 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 1.1750071409542542, 'learning_rate': 0.04100111570008403, 'max_depth': 3, 'min_child_weight': 6, 'subsample': 0.8106345363572656, 'colsample_bytree': 0.7387541919164202, 'lambda': 7.505412931478215, 'alpha': 3.0854733446305116}. Best is trial 4 with value: 0.8862736094554055.\n",
      "[I 2025-04-18 00:41:11,420] Trial 11 finished with value: 0.8577056287716563 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.3499057481301969, 'learning_rate': 0.005264412146151637, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.975925571746833, 'colsample_bytree': 0.8743188681917087, 'lambda': 9.615659806277025, 'alpha': 1.5253421517969639}. Best is trial 4 with value: 0.8862736094554055.\n",
      "[I 2025-04-18 00:41:13,518] Trial 12 finished with value: 0.8448043821254323 and parameters: {'aft_loss_distribution': 'logistic', 'aft_loss_distribution_scale': 0.2683757500475258, 'learning_rate': 0.0066932722175680965, 'max_depth': 5, 'min_child_weight': 4, 'subsample': 0.87340312128915, 'colsample_bytree': 0.8654680802510941, 'lambda': 4.0718409583398705, 'alpha': 0.4237442446919971}. Best is trial 4 with value: 0.8862736094554055.\n",
      "[I 2025-04-18 00:41:15,232] Trial 13 finished with value: 0.8594383112784764 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 1.0676916501410127, 'learning_rate': 0.015100028697229657, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.8638091044560919, 'colsample_bytree': 0.991820648280825, 'lambda': 0.33583801166264377, 'alpha': 0.837162331780115}. Best is trial 4 with value: 0.8862736094554055.\n",
      "[I 2025-04-18 00:41:17,723] Trial 14 finished with value: 0.881871524163265 and parameters: {'aft_loss_distribution': 'logistic', 'aft_loss_distribution_scale': 0.569149317229104, 'learning_rate': 0.04388006969615741, 'max_depth': 7, 'min_child_weight': 7, 'subsample': 0.9690462601419698, 'colsample_bytree': 0.8565299750485019, 'lambda': 3.8012932728193767, 'alpha': 0.2624380031209876}. Best is trial 4 with value: 0.8862736094554055.\n",
      "[I 2025-04-18 00:41:20,136] Trial 15 finished with value: 0.8868713229558471 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.1779148320600118, 'learning_rate': 0.0463045618790711, 'max_depth': 7, 'min_child_weight': 7, 'subsample': 0.9930744627111219, 'colsample_bytree': 0.7282788793943156, 'lambda': 3.327528914795915, 'alpha': 0.26420593825288}. Best is trial 15 with value: 0.8868713229558471.\n",
      "[I 2025-04-18 00:41:22,864] Trial 16 finished with value: 0.8809923157490538 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.19390998705622425, 'learning_rate': 0.09477828969476347, 'max_depth': 8, 'min_child_weight': 7, 'subsample': 0.7586172869841037, 'colsample_bytree': 0.7209628306934919, 'lambda': 1.1915055586548218, 'alpha': 0.10625721497327492}. Best is trial 15 with value: 0.8868713229558471.\n",
      "[I 2025-04-18 00:41:25,534] Trial 17 finished with value: 0.885728821906232 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.1726245196710726, 'learning_rate': 0.05397823269560661, 'max_depth': 8, 'min_child_weight': 9, 'subsample': 0.9993267511269681, 'colsample_bytree': 0.6997108097658562, 'lambda': 3.2557710049330173, 'alpha': 0.2550182021241144}. Best is trial 15 with value: 0.8868713229558471.\n",
      "[I 2025-04-18 00:41:27,828] Trial 18 finished with value: 0.880437388803047 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.613916922845098, 'learning_rate': 0.03948556236071221, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.7555018564674144, 'colsample_bytree': 0.7580874121245345, 'lambda': 0.28728382367882427, 'alpha': 0.2362769675510403}. Best is trial 15 with value: 0.8868713229558471.\n",
      "[I 2025-04-18 00:41:30,236] Trial 19 finished with value: 0.8833913130915112 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.10472658746527404, 'learning_rate': 0.06447312323183649, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.8362826201590952, 'colsample_bytree': 0.6803311436910329, 'lambda': 2.255111194757817, 'alpha': 0.5071213706926401}. Best is trial 15 with value: 0.8868713229558471.\n",
      "[I 2025-04-18 00:41:32,026] Trial 20 finished with value: 0.8584045600393511 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 1.50892273451647, 'learning_rate': 0.02162161978048856, 'max_depth': 4, 'min_child_weight': 10, 'subsample': 0.9354348266823662, 'colsample_bytree': 0.7936327546303418, 'lambda': 0.8342303885071236, 'alpha': 9.720432081137217}. Best is trial 15 with value: 0.8868713229558471.\n",
      "[I 2025-04-18 00:41:34,768] Trial 21 finished with value: 0.8844858494555939 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.2058468167019415, 'learning_rate': 0.053787334765041404, 'max_depth': 8, 'min_child_weight': 9, 'subsample': 0.9969532110212715, 'colsample_bytree': 0.6976651935231826, 'lambda': 3.234462428917108, 'alpha': 0.26362419199735904}. Best is trial 15 with value: 0.8868713229558471.\n",
      "[I 2025-04-18 00:41:37,908] Trial 22 finished with value: 0.8786537920627027 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.1715183380148012, 'learning_rate': 0.09986457673110047, 'max_depth': 9, 'min_child_weight': 8, 'subsample': 0.9404052868155786, 'colsample_bytree': 0.7202327463428321, 'lambda': 2.3980345904032716, 'alpha': 0.19311173547763338}. Best is trial 15 with value: 0.8868713229558471.\n",
      "[I 2025-04-18 00:41:41,022] Trial 23 finished with value: 0.8794862588263086 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.25845770665598145, 'learning_rate': 0.04962701909821603, 'max_depth': 9, 'min_child_weight': 9, 'subsample': 0.9995604238705242, 'colsample_bytree': 0.6027058963060834, 'lambda': 4.262402727044875, 'alpha': 0.30691634893026565}. Best is trial 15 with value: 0.8868713229558471.\n",
      "[I 2025-04-18 00:41:43,663] Trial 24 finished with value: 0.8857319343930814 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.14631274838261243, 'learning_rate': 0.032643032545658306, 'max_depth': 8, 'min_child_weight': 7, 'subsample': 0.9314296512948186, 'colsample_bytree': 0.8256584042386156, 'lambda': 1.4946476932774733, 'alpha': 0.5581710320977217}. Best is trial 15 with value: 0.8868713229558471.\n",
      "[I 2025-04-18 00:41:46,007] Trial 25 finished with value: 0.8858132483372184 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.1242600680894949, 'learning_rate': 0.03252687145834488, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.9316754076154603, 'colsample_bytree': 0.9064406701000566, 'lambda': 1.54094648140344, 'alpha': 0.5970585125773874}. Best is trial 15 with value: 0.8868713229558471.\n",
      "[I 2025-04-18 00:41:48,084] Trial 26 finished with value: 0.880219027262058 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.10012078005753854, 'learning_rate': 0.02205954075372552, 'max_depth': 6, 'min_child_weight': 6, 'subsample': 0.7508969996517771, 'colsample_bytree': 0.9523494463771042, 'lambda': 0.5669094901427543, 'alpha': 1.3842018106753067}. Best is trial 15 with value: 0.8868713229558471.\n",
      "[I 2025-04-18 00:41:50,595] Trial 27 finished with value: 0.8868789454475288 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.263057976364395, 'learning_rate': 0.06664628830757961, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.838153201124715, 'colsample_bytree': 0.9102937552683544, 'lambda': 1.3368348824813558, 'alpha': 0.13528037249994987}. Best is trial 27 with value: 0.8868789454475288.\n",
      "[I 2025-04-18 00:41:52,648] Trial 28 finished with value: 0.8855300030096622 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.30089668225756905, 'learning_rate': 0.08118477817426611, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.693508399823031, 'colsample_bytree': 0.9964783934882797, 'lambda': 1.0534218074206894, 'alpha': 0.13348479418775522}. Best is trial 27 with value: 0.8868789454475288.\n",
      "[I 2025-04-18 00:41:54,805] Trial 29 finished with value: 0.8855546962007552 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.7712666035787817, 'learning_rate': 0.06599231110208283, 'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.6029757934695248, 'colsample_bytree': 0.9093716412767583, 'lambda': 2.077701409817635, 'alpha': 0.102314174892901}. Best is trial 27 with value: 0.8868789454475288.\n",
      "[I 2025-04-18 00:41:56,658] Trial 30 finished with value: 0.8826984362780927 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.2231913559560335, 'learning_rate': 0.07290906078931016, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.7817430617174828, 'colsample_bytree': 0.9609203851545828, 'lambda': 5.669533468278226, 'alpha': 0.18916807144958211}. Best is trial 27 with value: 0.8868789454475288.\n",
      "[I 2025-04-18 00:41:59,113] Trial 31 finished with value: 0.8862859310333523 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.13436032515105617, 'learning_rate': 0.03653375394615284, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.9567949953092129, 'colsample_bytree': 0.8954949422123385, 'lambda': 1.2215016943855388, 'alpha': 0.3311967764578901}. Best is trial 27 with value: 0.8868789454475288.\n",
      "[I 2025-04-18 00:42:01,548] Trial 32 finished with value: 0.8866010143952237 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.14975290835275032, 'learning_rate': 0.03742090807624038, 'max_depth': 7, 'min_child_weight': 7, 'subsample': 0.8404336026768802, 'colsample_bytree': 0.8281877921642571, 'lambda': 0.7464508705541443, 'alpha': 0.35283056626194165}. Best is trial 27 with value: 0.8868789454475288.\n",
      "[I 2025-04-18 00:42:03,839] Trial 33 finished with value: 0.8780591783045931 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 1.8444180166680573, 'learning_rate': 0.026829299916825273, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.8444868291753084, 'colsample_bytree': 0.8876302343105127, 'lambda': 0.7259841066456512, 'alpha': 0.3519599277277118}. Best is trial 27 with value: 0.8868789454475288.\n",
      "[I 2025-04-18 00:42:06,337] Trial 34 finished with value: 0.8825800566558996 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.41544413623946663, 'learning_rate': 0.034788204239047334, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.9642026649910496, 'colsample_bytree': 0.9284052716789328, 'lambda': 0.5499086091072427, 'alpha': 0.1442107772669262}. Best is trial 27 with value: 0.8868789454475288.\n",
      "[I 2025-04-18 00:42:08,820] Trial 35 finished with value: 0.8874368142182785 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.14802229440888517, 'learning_rate': 0.04411864798226019, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.8974135430551088, 'colsample_bytree': 0.8345486756083257, 'lambda': 0.3310435817832798, 'alpha': 0.3540252827672498}. Best is trial 35 with value: 0.8874368142182785.\n",
      "[I 2025-04-18 00:42:11,530] Trial 36 finished with value: 0.8868273515302655 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.1676460156733953, 'learning_rate': 0.04738347377604533, 'max_depth': 8, 'min_child_weight': 8, 'subsample': 0.8374221100535405, 'colsample_bytree': 0.8358268769053839, 'lambda': 0.2862245680710331, 'alpha': 1.160916086398149}. Best is trial 35 with value: 0.8874368142182785.\n",
      "[I 2025-04-18 00:42:15,083] Trial 37 finished with value: 0.8782121073040566 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.3360789141922545, 'learning_rate': 0.018628296314238166, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.9042968828584174, 'colsample_bytree': 0.7876620128733746, 'lambda': 0.18070511794350297, 'alpha': 1.270586573390786}. Best is trial 35 with value: 0.8874368142182785.\n",
      "[I 2025-04-18 00:42:18,017] Trial 38 finished with value: 0.8852171220136609 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.2531279950444667, 'learning_rate': 0.04726728301776388, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.8749108482637231, 'colsample_bytree': 0.8280998427268167, 'lambda': 0.294066026376214, 'alpha': 3.713545648986927}. Best is trial 35 with value: 0.8874368142182785.\n",
      "[I 2025-04-18 00:42:20,692] Trial 39 finished with value: 0.87767275137744 and parameters: {'aft_loss_distribution': 'logistic', 'aft_loss_distribution_scale': 0.5610663950882426, 'learning_rate': 0.05937091196961931, 'max_depth': 8, 'min_child_weight': 8, 'subsample': 0.8223731604093232, 'colsample_bytree': 0.8430229199359084, 'lambda': 0.20578605327607083, 'alpha': 1.1166652771881889}. Best is trial 35 with value: 0.8874368142182785.\n",
      "[I 2025-04-18 00:42:23,286] Trial 40 finished with value: 0.8827705405875694 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.20370976446021158, 'learning_rate': 0.027834983064521944, 'max_depth': 8, 'min_child_weight': 6, 'subsample': 0.7896139672699336, 'colsample_bytree': 0.7713328610958157, 'lambda': 0.4034873311237667, 'alpha': 2.0077520160409947}. Best is trial 35 with value: 0.8874368142182785.\n",
      "[I 2025-04-18 00:42:25,659] Trial 41 finished with value: 0.8871497835078979 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.1568415369219105, 'learning_rate': 0.047718525104438365, 'max_depth': 7, 'min_child_weight': 7, 'subsample': 0.8463792659786818, 'colsample_bytree': 0.8218725112473012, 'lambda': 0.42543233316336493, 'alpha': 0.6267685347187839}. Best is trial 35 with value: 0.8874368142182785.\n",
      "[I 2025-04-18 00:42:27,849] Trial 42 finished with value: 0.8859182457363153 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.16042070352447801, 'learning_rate': 0.04633108701531496, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.8528289433384352, 'colsample_bytree': 0.8116571168568605, 'lambda': 0.2020388426157224, 'alpha': 0.7235457362650672}. Best is trial 35 with value: 0.8874368142182785.\n",
      "[I 2025-04-18 00:42:30,339] Trial 43 finished with value: 0.8867863201413414 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.12679317670007123, 'learning_rate': 0.06608741843424748, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.8910485103369649, 'colsample_bytree': 0.8405707459730991, 'lambda': 0.41654310156313173, 'alpha': 0.669231595166639}. Best is trial 35 with value: 0.8874368142182785.\n",
      "[I 2025-04-18 00:42:32,300] Trial 44 finished with value: 0.8560031298227129 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.23341130862341494, 'learning_rate': 0.010478313135863702, 'max_depth': 6, 'min_child_weight': 8, 'subsample': 0.9066275211464697, 'colsample_bytree': 0.7429788656748539, 'lambda': 0.15694873175171373, 'alpha': 1.0104124980524867}. Best is trial 35 with value: 0.8874368142182785.\n",
      "[I 2025-04-18 00:42:34,929] Trial 45 finished with value: 0.8013576582546859 and parameters: {'aft_loss_distribution': 'logistic', 'aft_loss_distribution_scale': 0.30675067572509823, 'learning_rate': 0.051743449118668926, 'max_depth': 8, 'min_child_weight': 9, 'subsample': 0.8264669359650726, 'colsample_bytree': 0.8080310037937097, 'lambda': 0.2592329002447158, 'alpha': 0.4511809757402866}. Best is trial 35 with value: 0.8874368142182785.\n",
      "[I 2025-04-18 00:42:36,786] Trial 46 finished with value: 0.848687473383906 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 7.409421419324735, 'learning_rate': 0.08300031655012094, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.8035994061144088, 'colsample_bytree': 0.8732425001731564, 'lambda': 0.23191298912727162, 'alpha': 1.698536790622577}. Best is trial 35 with value: 0.8874368142182785.\n",
      "[I 2025-04-18 00:42:38,995] Trial 47 finished with value: 0.8847667651855649 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.17736896741066427, 'learning_rate': 0.041663364485751975, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.8820762279879095, 'colsample_bytree': 0.7750986868837583, 'lambda': 0.3734747039351315, 'alpha': 0.19441708322987766}. Best is trial 35 with value: 0.8874368142182785.\n",
      "[I 2025-04-18 00:42:41,886] Trial 48 finished with value: 0.7720085800293303 and parameters: {'aft_loss_distribution': 'logistic', 'aft_loss_distribution_scale': 0.12039822404073665, 'learning_rate': 0.0617683028729751, 'max_depth': 9, 'min_child_weight': 7, 'subsample': 0.8578092276045921, 'colsample_bytree': 0.9301305920826725, 'lambda': 0.48282168086445093, 'alpha': 2.1426537323130117}. Best is trial 35 with value: 0.8874368142182785.\n",
      "[I 2025-04-18 00:42:44,510] Trial 49 finished with value: 0.8845710739375618 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.4123027783708082, 'learning_rate': 0.07358519737542285, 'max_depth': 8, 'min_child_weight': 6, 'subsample': 0.7774745157844057, 'colsample_bytree': 0.6428147766501604, 'lambda': 0.14104647101334872, 'alpha': 0.8520380268440119}. Best is trial 35 with value: 0.8874368142182785.\n",
      "[I 2025-04-18 00:42:47,019] Trial 50 finished with value: 0.884272300974372 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.27296725650542303, 'learning_rate': 0.04530894511848449, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.8205459642997539, 'colsample_bytree': 0.8862801994625154, 'lambda': 0.33337107737715704, 'alpha': 0.4538962205330482}. Best is trial 35 with value: 0.8874368142182785.\n",
      "[I 2025-04-18 00:42:49,425] Trial 51 finished with value: 0.8858005461705537 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.132022025516802, 'learning_rate': 0.06886453781397464, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.8841207017389205, 'colsample_bytree': 0.8467853791725611, 'lambda': 0.43875828468156625, 'alpha': 0.6316035557246102}. Best is trial 35 with value: 0.8874368142182785.\n",
      "[I 2025-04-18 00:42:51,905] Trial 52 finished with value: 0.8858739163588327 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.15622506936627617, 'learning_rate': 0.05666739218796728, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.8951775393846861, 'colsample_bytree': 0.8367080526397059, 'lambda': 0.6186256077069534, 'alpha': 0.6392283805259928}. Best is trial 35 with value: 0.8874368142182785.\n",
      "[I 2025-04-18 00:42:54,622] Trial 53 finished with value: 0.8811039221463122 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.1130533266328684, 'learning_rate': 0.0862330994436369, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.9163005715503684, 'colsample_bytree': 0.8561236999778953, 'lambda': 0.9379173208361068, 'alpha': 0.40808767734404655}. Best is trial 35 with value: 0.8874368142182785.\n",
      "[I 2025-04-18 00:42:56,819] Trial 54 finished with value: 0.8847201196377977 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.1902010758805782, 'learning_rate': 0.04196797849647679, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.8607071971602781, 'colsample_bytree': 0.7939567166279452, 'lambda': 0.10655926940617087, 'alpha': 0.7095709935094872}. Best is trial 35 with value: 0.8874368142182785.\n",
      "[I 2025-04-18 00:42:59,453] Trial 55 finished with value: 0.8877437470851564 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.2130485289669934, 'learning_rate': 0.059740737212314765, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.916757995367671, 'colsample_bytree': 0.8181370797612969, 'lambda': 0.3405440754959312, 'alpha': 4.6759060905994625}. Best is trial 55 with value: 0.8877437470851564.\n",
      "[I 2025-04-18 00:43:02,393] Trial 56 finished with value: 0.8824824429323025 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.22497016996234928, 'learning_rate': 0.029553422520819973, 'max_depth': 9, 'min_child_weight': 6, 'subsample': 0.9202534206195275, 'colsample_bytree': 0.7506851340735534, 'lambda': 0.31686400708200946, 'alpha': 6.280580203014247}. Best is trial 55 with value: 0.8877437470851564.\n",
      "[I 2025-04-18 00:43:05,153] Trial 57 finished with value: 0.8733698531822452 and parameters: {'aft_loss_distribution': 'logistic', 'aft_loss_distribution_scale': 0.4873821498017422, 'learning_rate': 0.05186890147651796, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.9485195790980698, 'colsample_bytree': 0.8143101105522166, 'lambda': 0.24641731919248663, 'alpha': 2.966913283155764}. Best is trial 55 with value: 0.8877437470851564.\n",
      "[I 2025-04-18 00:43:07,817] Trial 58 finished with value: 0.8841394675852576 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.3223747624328447, 'learning_rate': 0.03993289729188277, 'max_depth': 8, 'min_child_weight': 7, 'subsample': 0.9765285636593293, 'colsample_bytree': 0.7829177534247949, 'lambda': 2.0378534590735846, 'alpha': 4.401612420657361}. Best is trial 55 with value: 0.8877437470851564.\n",
      "[I 2025-04-18 00:43:11,385] Trial 59 finished with value: 0.8811044794922432 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.1897649179336885, 'learning_rate': 0.05686034326981971, 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8685404174215956, 'colsample_bytree': 0.7227671990842935, 'lambda': 0.6495190130724081, 'alpha': 0.220657763537498}. Best is trial 55 with value: 0.8877437470851564.\n",
      "[I 2025-04-18 00:43:13,881] Trial 60 finished with value: 0.88886722078601 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.3563253359779637, 'learning_rate': 0.09063846463307294, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.8356992326488509, 'colsample_bytree': 0.9690171324318362, 'lambda': 2.9287633042919166, 'alpha': 7.542816373061915}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:43:16,327] Trial 61 finished with value: 0.8887251834899241 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.36918835525492055, 'learning_rate': 0.08409561845582612, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.8309085428922408, 'colsample_bytree': 0.9717487647390483, 'lambda': 3.2713462162082605, 'alpha': 8.635292307939922}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:43:18,743] Trial 62 finished with value: 0.8881295594685422 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.6770275361946978, 'learning_rate': 0.09096587739038915, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.8112453642319559, 'colsample_bytree': 0.9812329876149716, 'lambda': 3.1637750234247592, 'alpha': 7.709087389154653}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:43:21,106] Trial 63 finished with value: 0.8870248949444969 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.7858047104629486, 'learning_rate': 0.08781297235196234, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.7959981692442476, 'colsample_bytree': 0.9654785087383165, 'lambda': 5.4007049278939245, 'alpha': 7.394897806288525}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:43:23,369] Trial 64 finished with value: 0.8858900672695748 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.8034908247055444, 'learning_rate': 0.09029072511870316, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.7929144270496292, 'colsample_bytree': 0.9688440153873864, 'lambda': 4.970348207966936, 'alpha': 7.545682788941327}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:43:25,744] Trial 65 finished with value: 0.8876899339726998 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.7549426013565266, 'learning_rate': 0.0992004394027782, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.8137134649843122, 'colsample_bytree': 0.9785548298542103, 'lambda': 7.650142921455141, 'alpha': 5.7455953539722024}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:43:27,731] Trial 66 finished with value: 0.8835857285488015 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 1.1341861110857308, 'learning_rate': 0.09440801455136606, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.8123877096545763, 'colsample_bytree': 0.9812803944735133, 'lambda': 8.150700102693483, 'alpha': 5.205631905171604}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:43:30,179] Trial 67 finished with value: 0.8876151223715355 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.48440416747702114, 'learning_rate': 0.07968199666380547, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.7689983992909677, 'colsample_bytree': 0.9389406230554695, 'lambda': 6.926404592903818, 'alpha': 8.190909654767369}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:43:32,437] Trial 68 finished with value: 0.8862368773859549 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.6426030045267807, 'learning_rate': 0.07891666292289859, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.7343730442469318, 'colsample_bytree': 0.9457201043488495, 'lambda': 6.9072096509742815, 'alpha': 8.276831607428432}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:43:34,923] Trial 69 finished with value: 0.8824946502690802 and parameters: {'aft_loss_distribution': 'logistic', 'aft_loss_distribution_scale': 0.5319046489849963, 'learning_rate': 0.0755735154280611, 'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.7627250543459325, 'colsample_bytree': 0.9771130932846326, 'lambda': 2.7299647455431373, 'alpha': 5.4821832045303065}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:43:37,219] Trial 70 finished with value: 0.8851527783280625 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.9637876047335171, 'learning_rate': 0.09862056359919054, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.7388649946928937, 'colsample_bytree': 0.9488096731649395, 'lambda': 8.63503884224716, 'alpha': 9.109507538035185}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:43:39,672] Trial 71 finished with value: 0.8879684156128533 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.4546462337449643, 'learning_rate': 0.08132110753007453, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.709976417215746, 'colsample_bytree': 0.9994279536970075, 'lambda': 3.5931482565329973, 'alpha': 6.223616773175341}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:43:42,133] Trial 72 finished with value: 0.8886373590826488 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.3696729356526018, 'learning_rate': 0.08089743518683144, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.7677467382645945, 'colsample_bytree': 0.999510181002295, 'lambda': 6.631144183522444, 'alpha': 6.364418879821016}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:43:44,401] Trial 73 finished with value: 0.8856605249062703 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.6725673991094797, 'learning_rate': 0.08441943761926138, 'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.7025560448184665, 'colsample_bytree': 0.9914717716134513, 'lambda': 6.657941395695515, 'alpha': 6.432365979033899}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:43:46,832] Trial 74 finished with value: 0.8881407826074118 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.37486825893197084, 'learning_rate': 0.07094586138055002, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.6688742056467208, 'colsample_bytree': 0.9851355536270354, 'lambda': 4.572951290241587, 'alpha': 4.3134908208341685}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:43:49,499] Trial 75 finished with value: 0.8870986481153262 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.3596125616252898, 'learning_rate': 0.07241497730028584, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.6400445440915852, 'colsample_bytree': 0.9993118870004545, 'lambda': 4.202427826646969, 'alpha': 4.234353701205343}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:43:51,927] Trial 76 finished with value: 0.8884396686094218 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.4247584720562293, 'learning_rate': 0.09258436518996004, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.6681220406422527, 'colsample_bytree': 0.9818315316477638, 'lambda': 3.649659457297384, 'alpha': 6.217367818891777}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:43:54,180] Trial 77 finished with value: 0.8876976547314328 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.37887505528668, 'learning_rate': 0.09154721010625033, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.6656999142952724, 'colsample_bytree': 0.9867770642782265, 'lambda': 3.599171518047606, 'alpha': 4.444148872045257}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:43:56,692] Trial 78 finished with value: 0.8878642333750977 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.4330074869115056, 'learning_rate': 0.07156965177250522, 'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.6814583753181641, 'colsample_bytree': 0.9574785588604985, 'lambda': 2.8020015239555387, 'alpha': 6.815301776172399}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:43:59,132] Trial 79 finished with value: 0.8881014666171627 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.43687555725964305, 'learning_rate': 0.0695807101010774, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.7074272176578853, 'colsample_bytree': 0.9592217030569269, 'lambda': 2.815403542006785, 'alpha': 6.7281432354056845}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:44:01,594] Trial 80 finished with value: 0.8880590089744187 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.5023528606836702, 'learning_rate': 0.07824008776818282, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.7067901593772948, 'colsample_bytree': 0.9695053726778254, 'lambda': 1.782142973505239, 'alpha': 3.60404768387689}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:44:04,043] Trial 81 finished with value: 0.8879641899510177 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.5043737348574615, 'learning_rate': 0.07883206327876319, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.7100339628707374, 'colsample_bytree': 0.9722648311361357, 'lambda': 1.8527482765062468, 'alpha': 3.6168741461224228}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:44:06,590] Trial 82 finished with value: 0.8876137391518099 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.3942471933922712, 'learning_rate': 0.08753716201683585, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6620039575864763, 'colsample_bytree': 0.9599527363469649, 'lambda': 4.741518620949403, 'alpha': 9.279063197646831}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:44:09,011] Trial 83 finished with value: 0.8867214380589434 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.44883945101850314, 'learning_rate': 0.06384911262910538, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.6433224983687339, 'colsample_bytree': 0.9880156174675598, 'lambda': 2.931763433675287, 'alpha': 5.040269983726805}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:44:11,425] Trial 84 finished with value: 0.8871497843116707 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.5884414783067987, 'learning_rate': 0.06842532189196343, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6796897886462113, 'colsample_bytree': 0.9994274023745323, 'lambda': 3.6633725232994983, 'alpha': 3.8340247876566713}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:44:13,613] Trial 85 finished with value: 0.8861220564809291 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.9106592321290115, 'learning_rate': 0.09251207629790527, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.7086441691566845, 'colsample_bytree': 0.9401249332439348, 'lambda': 2.5275699446652267, 'alpha': 5.903130648638172}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:44:16,072] Trial 86 finished with value: 0.8882700549078861 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.29558683425168214, 'learning_rate': 0.07673629033020396, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.7247214593800388, 'colsample_bytree': 0.967714377980564, 'lambda': 3.1358131396129534, 'alpha': 7.460993772963141}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:44:18,290] Trial 87 finished with value: 0.8860359580535905 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.3530166607463459, 'learning_rate': 0.07328123263770747, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.6245870151072217, 'colsample_bytree': 0.9184164654340984, 'lambda': 4.532899455966586, 'alpha': 7.232513282475723}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:44:21,101] Trial 88 finished with value: 0.7892515639532673 and parameters: {'aft_loss_distribution': 'logistic', 'aft_loss_distribution_scale': 0.29345018199293205, 'learning_rate': 0.08391243529067217, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.7287049367465572, 'colsample_bytree': 0.9830408913484222, 'lambda': 1.750011927359488, 'alpha': 8.161448621633719}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:44:23,346] Trial 89 finished with value: 0.879331843000158 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 1.2990752871441729, 'learning_rate': 0.06313693972823234, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6889095226784616, 'colsample_bytree': 0.9692873368807865, 'lambda': 3.0817919078709535, 'alpha': 9.895490950502252}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:44:25,810] Trial 90 finished with value: 0.8882021074700279 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.7074629547814203, 'learning_rate': 0.09844819120046974, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.7497007730528075, 'colsample_bytree': 0.9546598703410386, 'lambda': 2.329360294427154, 'alpha': 3.4041668100446683}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:44:28,311] Trial 91 finished with value: 0.8883715312215342 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.5441732012612998, 'learning_rate': 0.09548588183173382, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.7806272315431256, 'colsample_bytree': 0.9527265776525451, 'lambda': 2.386184306787147, 'alpha': 3.144817476931615}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:44:30,798] Trial 92 finished with value: 0.8887821906747044 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.6222961869804476, 'learning_rate': 0.09879344028921114, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.7490708040686079, 'colsample_bytree': 0.954069977902362, 'lambda': 2.1779644667471625, 'alpha': 3.0499715026477388}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:44:33,247] Trial 93 finished with value: 0.8874956300762892 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.6544584432782246, 'learning_rate': 0.09975366260259834, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.7504778972499884, 'colsample_bytree': 0.9323733938534882, 'lambda': 2.3515912003331993, 'alpha': 2.50084701138238}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:44:35,648] Trial 94 finished with value: 0.8873888568828396 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.8882559596976697, 'learning_rate': 0.09258662618796816, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.746272754269284, 'colsample_bytree': 0.9495447094839035, 'lambda': 2.1812252921124964, 'alpha': 3.013952858197434}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:44:38,138] Trial 95 finished with value: 0.8883047899424633 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.5700102974817209, 'learning_rate': 0.08941208827105436, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.7888015264164767, 'colsample_bytree': 0.9232276928549991, 'lambda': 3.337379470316373, 'alpha': 2.570600165778191}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:44:40,866] Trial 96 finished with value: 0.8885427300912992 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.5744365757174799, 'learning_rate': 0.08341993258730529, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.7817911190996681, 'colsample_bytree': 0.9398381852318354, 'lambda': 3.9481799976114718, 'alpha': 2.5846934604167466}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:44:43,359] Trial 97 finished with value: 0.8682224185391023 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.7007557158983037, 'learning_rate': 0.009611549265201042, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.7774763014418841, 'colsample_bytree': 0.9164299663004519, 'lambda': 2.564879697447656, 'alpha': 2.521652569173727}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:44:46,068] Trial 98 finished with value: 0.887739946250554 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.576679635321437, 'learning_rate': 0.08624862307422725, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.7690960107593555, 'colsample_bytree': 0.9395656021964109, 'lambda': 1.43469918366541, 'alpha': 1.8515346942435789}. Best is trial 60 with value: 0.88886722078601.\n",
      "[I 2025-04-18 00:44:48,319] Trial 99 finished with value: 0.8691657023355954 and parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.31781210482846634, 'learning_rate': 0.012445356516560748, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.782875300357143, 'colsample_bytree': 0.9254451746492588, 'lambda': 4.040479158346687, 'alpha': 1.5435542151874981}. Best is trial 60 with value: 0.88886722078601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'aft_loss_distribution': 'normal', 'aft_loss_distribution_scale': 0.3563253359779637, 'learning_rate': 0.09063846463307294, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.8356992326488509, 'colsample_bytree': 0.9690171324318362, 'lambda': 2.9287633042919166, 'alpha': 7.542816373061915}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Sample hyperparameters from a 9 dimensional search space\n",
    "    params = {\n",
    "        'objective': 'survival:aft',\n",
    "        'eval_metric': 'aft-nloglik',\n",
    "        'aft_loss_distribution': trial.suggest_categorical('aft_loss_distribution', ['logistic', 'normal']),\n",
    "        'aft_loss_distribution_scale': trial.suggest_loguniform('aft_loss_distribution_scale', 0.1, 10.0),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
    "        'lambda': trial.suggest_loguniform('lambda', 0.1, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 0.1, 10.0),\n",
    "        'tree_method': 'hist', \n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    df_train_copy1 = df_train1.copy()  \n",
    "    y_train1 = df_train[['efs','efs_time']]\n",
    "    categ_data = df_train_copy1.select_dtypes(include='object').columns.tolist()\n",
    "    num_data = df_train_copy1.drop([\"efs\", \"efs_time\", \"ID\"], axis=1).select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for train_index, val_index in skf.split(df_train_copy1, df_train_copy1['efs']): \n",
    "        X_train, X_val = df_train_copy1.iloc[train_index], df_train_copy1.iloc[val_index]\n",
    "        y_tr, y_val = y_train1.iloc[train_index], y_train1.iloc[val_index]\n",
    "        \n",
    "        y_lower_bound_tr = y_tr['efs_time']        \n",
    "        y_lower_bound_val = y_val['efs_time'] \n",
    "        y_upper_bound_tr = np.where(y_tr['efs']==0, np.inf,y_tr['efs_time'] )\n",
    "        y_upper_bound_val = np.where(y_val['efs']==0, np.inf,y_val['efs_time'] )\n",
    "\n",
    "        preprocessor = create_preprocessor(categ_data, num_data)\n",
    "\n",
    "        X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "        X_val_transformed = preprocessor.transform(X_val)\n",
    "\n",
    "        \n",
    "        dtrain_cv = xgb.DMatrix(X_train_transformed)\n",
    "        dval_cv = xgb.DMatrix(X_val_transformed)\n",
    "        dtrain_cv.set_float_info('label_lower_bound', y_lower_bound_tr)\n",
    "        dtrain_cv.set_float_info('label_upper_bound', y_upper_bound_tr)\n",
    "\n",
    "        dval_cv.set_float_info('label_lower_bound', y_lower_bound_val)\n",
    "        dval_cv.set_float_info('label_upper_bound', y_upper_bound_val)\n",
    "\n",
    "\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain_cv,\n",
    "            num_boost_round=200,\n",
    "            evals=[(dval_cv, \"validation\")],\n",
    "            verbose_eval=False\n",
    "        )\n",
    "\n",
    "\n",
    "    \n",
    "        preds = -booster.predict(dval_cv)\n",
    "        submission = pd.DataFrame({'ID': X_val[\"ID\"], 'prediction': preds}) \n",
    "        score_aft= score(X_val.copy(deep=True), submission.copy(deep=True), \"ID\")\n",
    "        results.append(score_aft)\n",
    "\n",
    "\n",
    "    return np.mean(results)\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction='maximize',pruner = pruner, sampler=optuna.samplers.TPESampler(seed=42)) \n",
    "study.optimize(objective, n_trials=100)  \n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best parameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final parameters:\n",
    "\n",
    "final_params = {\n",
    "    'objective': 'survival:aft',\n",
    "    'eval_metric': 'aft-nloglik',\n",
    "    'tree_method': 'hist',\n",
    "    'seed': 42, \n",
    "    **best_params\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 8-fold cross validation using parameters from Optuna study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stratified c-index for fold 0: \n",
      "             SC-index: score_aft xgb_aft: 0.8856383400667769\n",
      "stratified c-index for fold 1: \n",
      "             SC-index: score_aft xgb_aft: 0.8835790703629994\n",
      "stratified c-index for fold 2: \n",
      "             SC-index: score_aft xgb_aft: 0.8883686643334778\n",
      "stratified c-index for fold 3: \n",
      "             SC-index: score_aft xgb_aft: 0.8786552380994533\n",
      "stratified c-index for fold 4: \n",
      "             SC-index: score_aft xgb_aft: 0.8922312671656006\n",
      "stratified c-index for fold 5: \n",
      "             SC-index: score_aft xgb_aft: 0.8892520185221634\n",
      "stratified c-index for fold 6: \n",
      "             SC-index: score_aft xgb_aft: 0.8860390558231056\n",
      "stratified c-index for fold 7: \n",
      "             SC-index: score_aft xgb_aft: 0.8842495233566185\n",
      "The mean performance is 0.8860016472162744 \n"
     ]
    }
   ],
   "source": [
    "n_splits = 8\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "target_features = ['efs', 'efs_time']\n",
    "results = []\n",
    "for i, (train_idx,test_idx) in enumerate(kfold.split(df_train1)):\n",
    "   \n",
    "    X_train = df_train1.iloc[train_idx].drop(columns = target_features)\n",
    "    y_train = df_train1.loc[train_idx,target_features]\n",
    "    X_val = df_train1.iloc[test_idx].drop(columns = target_features)\n",
    "    y_test = df_train1.loc[test_idx, target_features]\n",
    "\n",
    "    y_lower_bound_tr = y_train['efs_time']        \n",
    "    y_lower_bound_val = y_test['efs_time'] \n",
    "    y_upper_bound_tr = np.where(y_train['efs']==0, np.inf,y_train['efs_time'] )\n",
    "    y_upper_bound_val = np.where(y_test['efs']==0, np.inf,y_test['efs_time'] )\n",
    "\n",
    "    categ_data = df_train1.select_dtypes(include='object').columns.tolist()\n",
    "    num_data = df_train1.drop([\"efs\", \"efs_time\", \"ID\"], axis=1).select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "    processor = create_preprocessor(categ_data, num_data)\n",
    "    X_train_processed = processor.fit_transform(X_train)\n",
    "    X_val_processed =processor.transform(X_val)\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train_processed)\n",
    "    dtrain.set_float_info('label', y_train['efs_time']) \n",
    "    dtrain.set_float_info('label_lower_bound', y_lower_bound_tr)\n",
    "    dtrain.set_float_info('label_upper_bound', y_upper_bound_tr)\n",
    "\n",
    "    booster1 = xgb.train(final_params, dtrain, num_boost_round=100,\n",
    "                evals=[(dtrain, 'train')],verbose_eval=False)\n",
    "    \n",
    "    X_Val1  = xgb.DMatrix(X_val_processed)\n",
    "    X_Val1.set_float_info('label', y_test['efs_time'])\n",
    "    X_Val1.set_float_info('label_lower_bound', y_lower_bound_val)\n",
    "    X_Val1.set_float_info('label_upper_bound', y_upper_bound_val)\n",
    "\n",
    "\n",
    "\n",
    "    aft_preds = -booster1.predict(X_Val1)\n",
    "    submission = pd.DataFrame({'ID': df_train.iloc[test_idx][\"ID\"], 'prediction': aft_preds}) \n",
    "    score_aft = score(df_train.iloc[test_idx].copy(deep=True), submission.copy(deep=True), \"ID\")\n",
    "    results.append(score_aft)\n",
    "\n",
    "    \n",
    "    print(f\"stratified c-index for fold {i}: \\n \\\n",
    "            SC-index: score_aft xgb_aft: {score_aft}\")\n",
    "print(f\"The mean performance is {np.mean(results)} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluation on the df_val set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The stratified concordance score of AFT XGBoost on the validation set: 0.6468318190816368.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data_train, since we added a new column:\n",
    "\n",
    "categ_data = df_train.select_dtypes(include='object').columns.tolist()\n",
    "num_data = df_train.drop([\"efs\", \"efs_time\",\"ID\"], axis=1).select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "processor = create_preprocessor(categ_data, num_data)\n",
    "X_train1 = processor.fit_transform(df_train1)\n",
    "X_Val1 = processor.transform(df_val1)\n",
    "\n",
    "\n",
    "# Training on best parameters from Optuna study:\n",
    "\n",
    "y_lower_bound = df_train1['efs_time']\n",
    "y_upper_bound = np.where(df_train1['efs']==0, np.inf,df_train1['efs_time'] )\n",
    "dtrain = xgb.DMatrix(X_train1)\n",
    "dtrain.set_float_info('label', df_train1['efs_time']) \n",
    "\n",
    "dtrain.set_float_info('label_lower_bound', y_lower_bound)\n",
    "dtrain.set_float_info('label_upper_bound', y_upper_bound)\n",
    "booster1 = xgb.train(final_params, dtrain, num_boost_round=100,\n",
    "                evals=[(dtrain, 'train')],\n",
    "                verbose_eval=False)\n",
    "\n",
    "# Evaluating:\n",
    "\n",
    "X_Val11  = xgb.DMatrix(X_Val1)\n",
    "aft_preds1 = -booster1.predict(X_Val11)\n",
    "submission1 = pd.DataFrame({'ID': df_val[\"ID\"], 'prediction': aft_preds1}) \n",
    "score_aft1= score(df_val.copy(deep=True), submission1.copy(deep=True), \"ID\")\n",
    "print(f\" The stratified concordance score of AFT XGBoost on the validation set: {score_aft1}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_spring_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
