{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7580e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import set_config\n",
    "\n",
    "from lifelines import CoxPHFitter\n",
    "# import the score function\n",
    "%run -i ../examples/concordance_index.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4982bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_test= pd.read_csv(\"../data/test_validation_set.csv\")\n",
    "df_train = pd.read_csv(\"../data/train_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373ce4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing based on KNN imputation \n",
    "class MissingValueTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, null_list = [\"Missing Disease Status\", \"Missing disease status\"]):\n",
    "        self.null_list = null_list\n",
    "        self.columns = None\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transform = X.copy(deep = True)\n",
    "        X_transform.replace(self.null_list, np.nan, inplace = True)\n",
    "        return X_transform\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = X.columns\n",
    "        return self \n",
    "    \n",
    "    def get_feature_names_out(self, input_features = None):\n",
    "        return self.columns\n",
    "\n",
    "cat_cols = df_train.select_dtypes(include='O').columns\n",
    "preproc_sd = Pipeline(\n",
    "    [   \n",
    "        ('preprocessing',\n",
    "                ColumnTransformer([\n",
    "                                    ('cat_missing', MissingValueTransformer(), cat_cols),\n",
    "                                    ('ID_year_dropper', 'drop', [\"ID\", 'year_hct'])],\n",
    "                                    sparse_threshold=0,\n",
    "                                    remainder='passthrough',\n",
    "                                    verbose_feature_names_out=False,\n",
    "                                    force_int_remainder_cols=False\n",
    "                                ).set_output(transform=\"pandas\")\n",
    "        ),\n",
    "        (\n",
    "            \"encode_and_scale\",\n",
    "            ColumnTransformer(\n",
    "                [\n",
    "                    ('one_hot', \n",
    "                    OneHotEncoder(drop='first',\n",
    "                                    min_frequency = 0.001,\n",
    "                                    handle_unknown='ignore',\n",
    "                                    sparse_output= False\n",
    "                    ), \n",
    "                    cat_cols\n",
    "                    ),\n",
    "                    ('scale', StandardScaler(), ['donor_age', 'age_at_hct', 'karnofsky_score'])\n",
    "                ],\n",
    "                sparse_threshold=0,\n",
    "                remainder='passthrough',\n",
    "                verbose_feature_names_out=False,\n",
    "                force_int_remainder_cols=False\n",
    "            ).set_output(transform=\"pandas\")\n",
    "        ),\n",
    "        (\n",
    "            \"impute\",\n",
    "            KNNImputer().set_output(transform = \"pandas\")\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# cox propotional harzard model (with l2 l1 regularization parameters)\n",
    "def cph_model(train_preproc, X_test_preproc, l2, l1):\n",
    "\n",
    "    cph = CoxPHFitter(penalizer= l2, l1_ratio= l1)\n",
    "    cph.fit(train_preproc, duration_col='efs_time', event_col='efs')\n",
    "    preds = cph.predict_partial_hazard(X_test_preproc)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ec6efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(preds, X_test, solution):\n",
    "    prediction= pd.DataFrame({\"ID\":X_test[\"ID\"], \"prediction\":preds})\n",
    "    sc_score = score(solution.copy(deep=True), prediction.copy(deep=True), \"ID\")\n",
    "\n",
    "    return sc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dae317",
   "metadata": {},
   "source": [
    "## Fine tuning for the l1 l2 regularizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b282314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalizer_list = [0.0001, 0.001, 0.01]\n",
    "l1_ratio_list = [0.0, 0.01, 0.05]\n",
    "\n",
    "penalizer_lables = ['l2 = ' + str(p) for p in penalizer_list]\n",
    "l1_ratio_table = ['l1 = ' + str(l1) for l1 in l1_ratio_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60e652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_pipline = preproc_sd\n",
    "\n",
    "n_splits = 5\n",
    "kfold = KFold(n_splits = n_splits, shuffle = True, random_state = 42)\n",
    "target_features = ['efs', 'efs_time']\n",
    "sc_indexes = -1.0 * np.ones((n_splits, len(penalizer_list), len(l1_ratio_list))) \n",
    "\n",
    "for i, (train_idx,test_idx) in enumerate(kfold.split(df_train)):\n",
    "\n",
    "    X_train = df_train.iloc[train_idx].drop(columns = target_features)\n",
    "    y_train = df_train.loc[train_idx, target_features]\n",
    "\n",
    "    X_test = df_train.iloc[test_idx].drop(columns = target_features)\n",
    "    y_test = df_train.loc[test_idx, target_features]\n",
    "\n",
    "    preproc_pipline.fit(X_train)\n",
    "    X_train_preproc = preproc_pipline.transform(X_train)\n",
    "    X_test_preproc =preproc_pipline.transform(X_test)\n",
    "\n",
    "    train_preproc = pd.concat([X_train_preproc, y_train], axis=1)\n",
    "    solution = df_train.iloc[test_idx]\n",
    "\n",
    "    for j, p  in enumerate(penalizer_list):\n",
    "        for k, l1 in enumerate(l1_ratio_list):\n",
    "                preds_cph = cph_model(train_preproc, X_test_preproc, p, l1)\n",
    "                score_cph = eval(preds_cph, X_test, solution)\n",
    "                sc_indexes[i, j, k] = score_cph\n",
    "                print(f\"stratified c-index for fold {i}, penalizer {p}, l1_ratio {l1}: {score_cph}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b676fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_indexes_mean = sc_indexes.mean(axis = 0)\n",
    "sc_indexes_mean = pd.DataFrame(sc_indexes_mean,\n",
    "                               index = penalizer_lables,\n",
    "                               columns = l1_ratio_table)\n",
    "\n",
    "print(f\"mean stratified c-index: \\n {sc_indexes_mean}\")\n",
    "sc_indexes_mean.to_csv(\"finetuning_cph_results.csv\", sep='\\t', index= True, header= True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boost_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
