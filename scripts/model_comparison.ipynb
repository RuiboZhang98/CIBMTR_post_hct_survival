{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61e7cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import main_module as md\n",
    "\n",
    "# figure fonts configuration\n",
    "from matplotlib import rc\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7444601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import set_config\n",
    "\n",
    "from lifelines import CoxPHFitter\n",
    "# import the score function\n",
    "%run -i ../examples/concordance_index.ipynb\n",
    "\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.util import Surv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d6b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_test= pd.read_csv(\"../data/test_validation_set.csv\")\n",
    "df_train = pd.read_csv(\"../data/train_set.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ba1f77",
   "metadata": {},
   "source": [
    "## Data preprocessing pipelines\n",
    "In this section, we create pipelines for preprocessing the data. The main goal here is to investigate if data imputation improves the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d114a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive preprocessor\n",
    "# replace missing categorical variables by 'missing', replace missing numerical values by -1\n",
    "class NaiveDataTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.columns = None\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transform = X.copy(deep = True)\n",
    "        cat_cols = X_transform.select_dtypes(include = 'O').columns\n",
    "        num_cols = X_transform.select_dtypes(exclude = 'O').columns\n",
    "        X_transform[cat_cols] = X_transform[cat_cols].fillna(\"missing\")\n",
    "        X_transform[num_cols] = X_transform[num_cols].fillna(-1.0)\n",
    "        return X_transform\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = X.columns\n",
    "        return self \n",
    "    \n",
    "    def get_feature_names_out(self, input_features = None):\n",
    "        return self.columns\n",
    "\n",
    "cat_cols = df_train.select_dtypes(include='O').columns\n",
    "num_cols = df_train.select_dtypes(exclude='O').columns.drop([\"ID\", 'year_hct','efs', 'efs_time'])\n",
    "other_cols = df_train.columns.drop([\"ID\", 'year_hct','efs', 'efs_time'])\n",
    "# set_config(transform_output=\"pandas\")\n",
    "preproc_naive = Pipeline(\n",
    "    steps = [('preprocessing',\n",
    "                ColumnTransformer([('naive_missing', NaiveDataTransformer(), other_cols),\n",
    "                                ('ID_year_dropper', 'drop', [\"ID\", 'year_hct'])],\n",
    "                                    sparse_threshold=0,\n",
    "                                    remainder='passthrough',\n",
    "                                    verbose_feature_names_out=False,\n",
    "                                    force_int_remainder_cols=False\n",
    "                                ).set_output(transform=\"pandas\")\n",
    "            ),\n",
    "            ('naive_one_hot_encode',\n",
    "                ColumnTransformer([('one_hot', OneHotEncoder(drop='first',\n",
    "                                                             min_frequency = 0.001,\n",
    "                                                             handle_unknown='ignore',\n",
    "                                                             sparse_output= False), cat_cols)],\n",
    "                                    sparse_threshold=0,\n",
    "                                    remainder='passthrough',\n",
    "                                    verbose_feature_names_out=False,\n",
    "                                    force_int_remainder_cols=False\n",
    "                                ).set_output(transform=\"pandas\")\n",
    "            )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5452c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing based on KNN imputation \n",
    "class MissingValueTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, null_list = [\"Missing Disease Status\", \"Missing disease status\"]):\n",
    "        self.null_list = null_list\n",
    "        self.columns = None\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transform = X.copy(deep = True)\n",
    "        X_transform.replace(self.null_list, np.nan, inplace = True)\n",
    "        return X_transform\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = X.columns\n",
    "        return self \n",
    "    \n",
    "    def get_feature_names_out(self, input_features = None):\n",
    "        return self.columns\n",
    "\n",
    "cat_cols = df_train.select_dtypes(include='O').columns\n",
    "preproc_sd = Pipeline(\n",
    "    [   \n",
    "        ('preprocessing',\n",
    "                ColumnTransformer([\n",
    "                                    ('cat_missing', MissingValueTransformer(), cat_cols),\n",
    "                                    ('ID_year_dropper', 'drop', [\"ID\", 'year_hct'])],\n",
    "                                    sparse_threshold=0,\n",
    "                                    remainder='passthrough',\n",
    "                                    verbose_feature_names_out=False,\n",
    "                                    force_int_remainder_cols=False\n",
    "                                ).set_output(transform=\"pandas\")\n",
    "        ),\n",
    "        (\n",
    "            \"encode_and_scale\",\n",
    "            ColumnTransformer(\n",
    "                [\n",
    "                    ('one_hot', \n",
    "                    OneHotEncoder(drop='first',\n",
    "                                    min_frequency = 0.001,\n",
    "                                    handle_unknown='ignore',\n",
    "                                    sparse_output= False\n",
    "                    ), \n",
    "                    cat_cols\n",
    "                    ),\n",
    "                    ('scale', StandardScaler(), ['donor_age', 'age_at_hct', 'karnofsky_score'])\n",
    "                ],\n",
    "                sparse_threshold=0,\n",
    "                remainder='passthrough',\n",
    "                verbose_feature_names_out=False,\n",
    "                force_int_remainder_cols=False\n",
    "            ).set_output(transform=\"pandas\")\n",
    "        ),\n",
    "        (\n",
    "            \"impute\",\n",
    "            KNNImputer().set_output(transform = \"pandas\")\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82651a10",
   "metadata": {},
   "source": [
    "## Modeling Methods\n",
    "\n",
    "In this section, we implement the actual modeling methods including \n",
    "* CoxPH model\n",
    "* XGboost AFT\n",
    "* Catboost AFT\n",
    "* Survival Random Foreast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cox propotional harzard model\n",
    "def cph_model(X_train_preproc, y_train, X_test_preproc):\n",
    "\n",
    "    train_preproc = pd.concat([X_train_preproc, y_train], axis=1)\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(train_preproc, duration_col='efs_time', event_col='efs')\n",
    "    preds = cph.predict_partial_hazard(X_test_preproc)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ddfc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGboost\n",
    "params = {'objective': 'survival:aft',\n",
    "          'eval_metric': 'aft-nloglik',\n",
    "          'aft_loss_distribution': 'normal',\n",
    "         'aft_loss_distribution_scale': 0.80,\n",
    "          'tree_method': 'hist', 'learning_rate': 0.05, 'max_depth': 6}\n",
    "   \n",
    "def xgb_aft_model(X_train_preproc, y_train, X_test_preproc, params = params):\n",
    "\n",
    "    # remove special character\n",
    "    X_train_preproc.columns = X_train_preproc.columns.str.replace('<','')\n",
    "    X_test_preproc.columns = X_test_preproc.columns.str.replace('<','')\n",
    "\n",
    "    y_lower_bound = y_train['efs_time'].copy(deep = True)\n",
    "    y_upper_bound = y_train['efs_time'].copy(deep = True)\n",
    "    y_upper_bound[y_train['efs'] == 0.0] = +np.inf\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train_preproc)\n",
    "    dtrain.set_float_info('label_lower_bound', y_lower_bound)\n",
    "    dtrain.set_float_info('label_upper_bound', y_upper_bound)\n",
    "\n",
    "    bst = xgb.train(params, dtrain, num_boost_round=500, evals=[(dtrain, 'train')], verbose_eval = 0)\n",
    "    dtest = xgb.DMatrix(X_test_preproc)\n",
    "    preds = bst.predict(dtest)\n",
    "\n",
    "    return -preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b7cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Catboost\n",
    "\n",
    "# catboost does not directly take one-hot encoding\n",
    "# instead, it requires an explicit declaration of catgorical features\n",
    "\n",
    "# Here are the modified pipelines for catboost\n",
    "# The basic idea is to remove the one-hot encoding process\n",
    "\n",
    "num_cols = df_train.select_dtypes(exclude='O').columns.drop([\"ID\", 'year_hct','efs', 'efs_time'])\n",
    "cb_preproc_naive = NaiveDataTransformer()\n",
    "cb_preproc_sd = Pipeline(\n",
    "    [   \n",
    "        ('preprocessing',\n",
    "                ColumnTransformer([\n",
    "                                    ('cat_missing', MissingValueTransformer(), cat_cols),\n",
    "                                    ('ID_year_dropper', 'drop', [\"ID\", 'year_hct']),\n",
    "                                    ('scale', StandardScaler(), ['donor_age', 'age_at_hct', 'karnofsky_score'])],\n",
    "                                    sparse_threshold=0,\n",
    "                                    remainder='passthrough',\n",
    "                                    verbose_feature_names_out=False,\n",
    "                                    force_int_remainder_cols=False\n",
    "                                ).set_output(transform=\"pandas\")\n",
    "        ),\n",
    "        ('impute',\n",
    "                ColumnTransformer([(\"num_KNNimpute\", KNNImputer(), num_cols),\n",
    "                                   (\"cat_indicate\", NaiveDataTransformer(), cat_cols)],\n",
    "                                    sparse_threshold=0,\n",
    "                                    remainder='passthrough',\n",
    "                                    verbose_feature_names_out=False,\n",
    "                                    force_int_remainder_cols=False\n",
    "                                ).set_output(transform=\"pandas\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def cb_aft_model(X_train, y_train, X_test, y_test, pipeline):\n",
    "\n",
    "    X_train_proc = pipeline.fit_transform(X_train)\n",
    "    X_test_proc = pipeline.fit_transform(X_test)\n",
    "\n",
    "    y_lower_train = y_train[['efs_time']].copy(deep = True)\n",
    "    y_upper_train = y_train[['efs_time']].copy(deep = True)\n",
    "    # in catboost, infinity is represented by -1\n",
    "    y_upper_train.iloc[y_train['efs'] == 0.0] = -1\n",
    "\n",
    "    train_label = np.concatenate((y_lower_train, y_upper_train), axis = 1)\n",
    "    train_label = pd.DataFrame(train_label, columns = ['y_lower_train', 'y_upper_train'])\n",
    "    cat_features = list(X_train.select_dtypes(include= 'O').columns)\n",
    "\n",
    "    y_lower_test = y_test[['efs_time']].copy(deep = True)\n",
    "    y_upper_test = y_test[['efs_time']].copy(deep = True)\n",
    "    # in catboost, infinity is represented by -1\n",
    "    y_upper_test.iloc[y_test['efs'] == 0.0] = -1\n",
    "    \n",
    "    test_label = np.concatenate((y_lower_test, y_upper_test), axis = 1)\n",
    "    test_label = pd.DataFrame(test_label, columns = ['y_lower_test', 'y_upper_test'])\n",
    "\n",
    "    train_pool = Pool(X_train_proc,label = train_label, cat_features= cat_features)\n",
    "    test_pool = Pool(X_test_proc,label = test_label, cat_features= cat_features)\n",
    "\n",
    "    model_normal = CatBoostRegressor(iterations=500,\n",
    "                                 loss_function='SurvivalAft:dist=Normal',\n",
    "                                 eval_metric='SurvivalAft',\n",
    "                                 verbose=0\n",
    "                                )\n",
    "    _ = model_normal.fit(train_pool, eval_set=test_pool)\n",
    "    preds = model_normal.predict(test_pool, prediction_type='Exponent')\n",
    "    \n",
    "    return -preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b409d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random survival forest\n",
    "def rsf_model(X_train_preproc, y_train, X_test_preproc):\n",
    "\n",
    "    y_train = Surv.from_dataframe(\"efs\", \"efs_time\", y_train)\n",
    "\n",
    "    rsf = RandomSurvivalForest(\n",
    "        n_estimators=30,\n",
    "        max_depth=10,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        n_jobs=4,\n",
    "        verbose=1,\n",
    "        random_state=42\n",
    "    )\n",
    "    rsf.fit(X_train_preproc, y_train)\n",
    "    surv_funcs = rsf.predict_survival_function(X_test_preproc, return_array=False)\n",
    "    preds = np.array([-np.trapz(fn.y, fn.x) for fn in surv_funcs])\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ecc78",
   "metadata": {},
   "source": [
    "## Five-fold Cross validation\n",
    "\n",
    "Here we use the five fold cross validation for getting a baseline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "# eval evalutes stratified c-index and c-index\n",
    "def eval(preds, X_test, solution):\n",
    "    prediction= pd.DataFrame({\"ID\":X_test[\"ID\"], \"prediction\":preds})\n",
    "    sc_score = score(solution.copy(deep=True), prediction.copy(deep=True), \"ID\")\n",
    "    c_index = concordance_index(y_test['efs_time'], -preds, y_test['efs'])\n",
    "\n",
    "    return sc_score, c_index\n",
    "\n",
    "# file_output export all the information into a csv file\n",
    "def file_output(filename, sc_indexes):\n",
    "    sc_mean = sc_indexes.mean()\n",
    "    output = pd.DataFrame(np.concatenate(\n",
    "                                        (sc_indexes.to_numpy(), np.expand_dims(sc_mean.to_numpy(), axis = 0)\n",
    "                                     ), axis = 0), \n",
    "                                     index=[0,1,2,3,4, 'mean'],\n",
    "                                     columns= ['cph', 'xgb_aft', 'cat_aft', 'rsf'])\n",
    "    output.to_csv(filename, sep= '\\t', index= True, header= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f5805",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_pipline = preproc_naive\n",
    "\n",
    "n_splits = 5\n",
    "kfold = KFold(n_splits = n_splits, shuffle = True, random_state = 42)\n",
    "target_features = ['efs', 'efs_time']\n",
    "\n",
    "methods_list = ['cph', 'xgb_aft', 'cat_aft', 'rsf']\n",
    "sc_indexes = -1.0 * np.ones((n_splits, len(methods_list))) \n",
    "sc_indexes = pd.DataFrame(data = sc_indexes, columns = methods_list)\n",
    "\n",
    "for i, (train_idx,test_idx) in enumerate(kfold.split(df_train)):\n",
    "\n",
    "    X_train = df_train.iloc[train_idx].drop(columns = target_features)\n",
    "    y_train = df_train.loc[train_idx, target_features]\n",
    "\n",
    "    X_test = df_train.iloc[test_idx].drop(columns = target_features)\n",
    "    y_test = df_train.loc[test_idx, target_features]\n",
    "\n",
    "    preproc_pipline.fit(X_train)\n",
    "    X_train_preproc = preproc_pipline.transform(X_train)\n",
    "    X_test_preproc =preproc_pipline.transform(X_test)\n",
    "    \n",
    "    preds_cph = cph_model(X_train_preproc, y_train, X_test_preproc)\n",
    "    preds_xgb = xgb_aft_model(X_train_preproc, y_train, X_test_preproc, params = params)\n",
    "    preds_cb = cb_aft_model(X_train, y_train, X_test, y_test, cb_preproc_naive)\n",
    "    preds_rsf = rsf_model(X_train_preproc, y_train, X_test_preproc)\n",
    "\n",
    "    solution = df_train.iloc[test_idx]\n",
    "    score_cph, c_index_cph = eval(preds_cph, X_test, solution)\n",
    "    score_xgb, c_index_xgb = eval(preds_xgb, X_test, solution)\n",
    "    score_cb, c_index_cb = eval(preds_cb, X_test, solution)\n",
    "    score_rsf, c_index_rsf = eval(preds_rsf, X_test, solution)\n",
    "\n",
    "    print(f\"stratified c-index for fold {i}: \\n \\\n",
    "            SC-index: cph: {score_cph}, xgb_aft: {score_xgb}, cat_aft: {score_cb}, rsf_aft: {score_rsf} \\n \\\n",
    "            C_index: cph: {c_index_cph}, xgb_aft: {c_index_xgb}, cat_aft: {c_index_cb}, rsf_aft: {c_index_rsf} \\n\")\n",
    "    \n",
    "    sc_indexes.loc[i, 'cph'] = score_cph\n",
    "    sc_indexes.loc[i, 'xgb_aft'] = score_xgb\n",
    "    sc_indexes.loc[i, 'cat_aft'] = score_cb\n",
    "    sc_indexes.loc[i, 'rsf'] = score_rsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb78e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean stratified c-index across all 5 folds:\")\n",
    "print(sc_indexes.mean())\n",
    "\n",
    "file_output('output_naive(baseline)_cv.csv', sc_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab26728",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_pipline = preproc_sd\n",
    "\n",
    "n_splits = 5\n",
    "kfold = KFold(n_splits = n_splits, shuffle = True, random_state = 42)\n",
    "target_features = ['efs', 'efs_time']\n",
    "\n",
    "methods_list = ['cph', 'xgb_aft', 'cat_aft', 'rsf']\n",
    "sc_indexes = -1.0 * np.ones((n_splits, len(methods_list))) \n",
    "sc_indexes = pd.DataFrame(data = sc_indexes, columns = methods_list)\n",
    "\n",
    "for i, (train_idx,test_idx) in enumerate(kfold.split(df_train)):\n",
    "\n",
    "    X_train = df_train.iloc[train_idx].drop(columns = target_features)\n",
    "    y_train = df_train.loc[train_idx, target_features]\n",
    "\n",
    "    X_test = df_train.iloc[test_idx].drop(columns = target_features)\n",
    "    y_test = df_train.loc[test_idx, target_features]\n",
    "\n",
    "    preproc_pipline.fit(X_train)\n",
    "    X_train_preproc = preproc_pipline.transform(X_train)\n",
    "    X_test_preproc =preproc_pipline.transform(X_test)\n",
    "    \n",
    "    preds_cph = cph_model(X_train_preproc, y_train, X_test_preproc)\n",
    "    preds_xgb = xgb_aft_model(X_train_preproc, y_train, X_test_preproc, params = params)\n",
    "    preds_cb = cb_aft_model(X_train, y_train, X_test, y_test, cb_preproc_sd)\n",
    "    preds_rsf = rsf_model(X_train_preproc, y_train, X_test_preproc)\n",
    "\n",
    "    solution = df_train.iloc[test_idx]\n",
    "    score_cph, c_index_cph = eval(preds_cph, X_test, solution)\n",
    "    score_xgb, c_index_xgb = eval(preds_xgb, X_test, solution)\n",
    "    score_cb, c_index_cb = eval(preds_cb, X_test, solution)\n",
    "    score_rsf, c_index_rsf = eval(preds_rsf, X_test, solution)\n",
    "\n",
    "    sc_indexes.loc[i, 'cph'] = score_cph\n",
    "    sc_indexes.loc[i, 'xgb_aft'] = score_xgb\n",
    "    sc_indexes.loc[i, 'cat_aft'] = score_cb\n",
    "    sc_indexes.loc[i, 'rsf'] = score_rsf\n",
    "\n",
    "    print(f\"stratified c-index for fold {i}: \\n \\\n",
    "            SC-index: cph: {score_cph}, xgb_aft: {score_xgb},  cat_aft: {score_cb}, rsf_aft: {score_rsf} \\n \\\n",
    "            C_index: cph: {c_index_cph}, xgb_aft: {c_index_xgb}, cat_aft: {c_index_cb}, rsf_aft: {c_index_rsf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb17c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ray pipeline mean stratified c-index across all 5 folds:\")\n",
    "print(sc_indexes.mean())\n",
    "\n",
    "file_output('output_proc(Ray)_cv.csv', sc_indexes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boost_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
