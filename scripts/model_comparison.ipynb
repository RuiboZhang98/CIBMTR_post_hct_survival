{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b61e7cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main module is loaded\n",
      "/home/rzhang98/code2025/CIBMTR_post_hct_survival/scripts/main_module.py\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import main_module as md\n",
    "\n",
    "# figure fonts configuration\n",
    "from matplotlib import rc\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7444601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import set_config\n",
    "\n",
    "from lifelines import CoxPHFitter\n",
    "# import the score function\n",
    "%run -i ../examples/concordance_index.ipynb\n",
    "\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe1d6b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_val_test= pd.read_csv(\"../data/test_validation_set.csv\")\n",
    "df_val, df_test = train_test_split(df_val_test, train_size= 0.5, random_state = 41, shuffle = True)\n",
    "df_train = pd.read_csv(\"../data/train_set.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ba1f77",
   "metadata": {},
   "source": [
    "## Data preprocessing pipelines\n",
    "In this section, we create pipelines for preprocessing the data. The main goal here is to investigate if data imputation improves the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d114a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive preprocessor\n",
    "# replace missing categorical variables by 'missing', replace missing numerical values by -1\n",
    "class NaiveDataTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.columns = None\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transform = X.copy(deep = True)\n",
    "        cat_cols = X_transform.select_dtypes(include = 'O').columns\n",
    "        num_cols = X_transform.select_dtypes(exclude = 'O').columns\n",
    "        X_transform[cat_cols] = X_transform[cat_cols].fillna(\"missing\")\n",
    "        X_transform[num_cols] = X_transform[num_cols].fillna(-1.0)\n",
    "        return X_transform\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = X.columns\n",
    "        return self \n",
    "    \n",
    "    def get_feature_names_out(self, input_features = None):\n",
    "        return self.columns\n",
    "\n",
    "cat_cols = df_train.select_dtypes(include='O').columns\n",
    "num_cols = df_train.select_dtypes(exclude='O').columns.drop([\"ID\", 'year_hct','efs', 'efs_time'])\n",
    "other_cols = df_train.columns.drop([\"ID\", 'year_hct','efs', 'efs_time'])\n",
    "# set_config(transform_output=\"pandas\")\n",
    "preproc_naive = Pipeline(\n",
    "    steps = [('preprocessing',\n",
    "                ColumnTransformer([('naive_missing', NaiveDataTransformer(), other_cols),\n",
    "                                ('ID_year_dropper', 'drop', [\"ID\", 'year_hct'])],\n",
    "                                    sparse_threshold=0,\n",
    "                                    remainder='passthrough',\n",
    "                                    verbose_feature_names_out=False,\n",
    "                                    force_int_remainder_cols=False\n",
    "                                ).set_output(transform=\"pandas\")\n",
    "            ),\n",
    "            ('naive_one_hot_encode',\n",
    "                ColumnTransformer([('one_hot', OneHotEncoder(drop='first',\n",
    "                                                             min_frequency = 0.001,\n",
    "                                                             handle_unknown='ignore',\n",
    "                                                             sparse_output= False), cat_cols)],\n",
    "                                    sparse_threshold=0,\n",
    "                                    remainder='passthrough',\n",
    "                                    verbose_feature_names_out=False,\n",
    "                                    force_int_remainder_cols=False\n",
    "                                ).set_output(transform=\"pandas\")\n",
    "            )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5452c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing based on KNN imputation \n",
    "class MissingValueTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, null_list = [\"Missing Disease Status\", \"Missing disease status\"]):\n",
    "        self.null_list = null_list\n",
    "        self.columns = None\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transform = X.copy(deep = True)\n",
    "        X_transform.replace(self.null_list, np.nan, inplace = True)\n",
    "        return X_transform\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = X.columns\n",
    "        return self \n",
    "    \n",
    "    def get_feature_names_out(self, input_features = None):\n",
    "        return self.columns\n",
    "\n",
    "cat_cols = df_train.select_dtypes(include='O').columns\n",
    "preproc_sd = Pipeline(\n",
    "    [   \n",
    "        ('preprocessing',\n",
    "                ColumnTransformer([\n",
    "                                    ('cat_missing', MissingValueTransformer(), cat_cols),\n",
    "                                    ('ID_year_dropper', 'drop', [\"ID\", 'year_hct'])],\n",
    "                                    sparse_threshold=0,\n",
    "                                    remainder='passthrough',\n",
    "                                    verbose_feature_names_out=False,\n",
    "                                    force_int_remainder_cols=False\n",
    "                                ).set_output(transform=\"pandas\")\n",
    "        ),\n",
    "        (\n",
    "            \"encode_and_scale\",\n",
    "            ColumnTransformer(\n",
    "                [\n",
    "                    ('one_hot', \n",
    "                    OneHotEncoder(drop='first',\n",
    "                                    min_frequency = 0.001,\n",
    "                                    handle_unknown='ignore',\n",
    "                                    sparse_output= False\n",
    "                    ), \n",
    "                    cat_cols\n",
    "                    ),\n",
    "                    ('scale', StandardScaler(), ['donor_age', 'age_at_hct', 'karnofsky_score'])\n",
    "                ],\n",
    "                sparse_threshold=0,\n",
    "                remainder='passthrough',\n",
    "                verbose_feature_names_out=False,\n",
    "                force_int_remainder_cols=False\n",
    "            ).set_output(transform=\"pandas\")\n",
    "        ),\n",
    "        (\n",
    "            \"impute\",\n",
    "            KNNImputer().set_output(transform = \"pandas\")\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82651a10",
   "metadata": {},
   "source": [
    "## Modeling Method\n",
    "\n",
    "In this section, we implement the actual modeling methods including CPH model, XGboost AFT, and Catboost AFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "713d495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cph_model(X_train_preproc, y_train, X_test_preproc):\n",
    "\n",
    "    train_preproc = pd.concat([X_train_preproc, y_train], axis=1)\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(train_preproc, duration_col='efs_time', event_col='efs')\n",
    "    preds = cph.predict_partial_hazard(X_test_preproc)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ddfc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGboost\n",
    "params = {'objective': 'survival:aft',\n",
    "          'eval_metric': 'aft-nloglik',\n",
    "          'aft_loss_distribution': 'normal',\n",
    "         'aft_loss_distribution_scale': 0.80,\n",
    "          'tree_method': 'hist', 'learning_rate': 0.05, 'max_depth': 6}\n",
    "   \n",
    "def xgb_aft_model(X_train_preproc, y_train, X_test_preproc, params = params):\n",
    "\n",
    "    # remove special character\n",
    "    X_train_preproc.columns = X_train_preproc.columns.str.replace('<','')\n",
    "    X_test_preproc.columns = X_test_preproc.columns.str.replace('<','')\n",
    "\n",
    "    y_lower_bound = y_train['efs_time'].copy(deep = True)\n",
    "    y_upper_bound = y_train['efs_time'].copy(deep = True)\n",
    "    y_upper_bound[y_train['efs'] == 0.0] = +np.inf\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train_preproc)\n",
    "    dtrain.set_float_info('label_lower_bound', y_lower_bound)\n",
    "    dtrain.set_float_info('label_upper_bound', y_upper_bound)\n",
    "\n",
    "    bst = xgb.train(params, dtrain, num_boost_round=500, evals=[(dtrain, 'train')], verbose_eval = 0)\n",
    "    dtest = xgb.DMatrix(X_test_preproc)\n",
    "    preds = bst.predict(dtest)\n",
    "\n",
    "    return -preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e7b7cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Catboost\n",
    "\n",
    "def cb_aft_model(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    # remove special character\n",
    "    nt = NaiveDataTransformer() \n",
    "    X_train_proc = nt.fit_transform(X_train)\n",
    "    X_test_proc = nt.fit_transform(X_test)\n",
    "\n",
    "    y_lower_train = y_train[['efs_time']].copy(deep = True)\n",
    "    y_upper_train = y_train[['efs_time']].copy(deep = True)\n",
    "    # in catboost, infinity is represented by -1\n",
    "    y_upper_train.iloc[y_train['efs'] == 0.0] = -1\n",
    "    train_label = np.concatenate((y_lower_train, y_upper_train), axis = 1)\n",
    "    train_label = pd.DataFrame(train_label, columns = ['y_lower_train', 'y_upper_train'])\n",
    "    cat_features = list(X_train.select_dtypes(include= 'O').columns)\n",
    "\n",
    "    y_lower_test = y_test[['efs_time']].copy(deep = True)\n",
    "    y_upper_test = y_test[['efs_time']].copy(deep = True)\n",
    "    # in catboost, infinity is represented by -1\n",
    "    y_upper_test.iloc[y_test['efs'] == 0.0] = -1\n",
    "    test_label = np.concatenate((y_lower_test, y_upper_test), axis = 1)\n",
    "    test_label = pd.DataFrame(test_label, columns = ['y_lower_test', 'y_upper_test'])\n",
    "\n",
    "    train_pool = Pool(X_train_proc,label = train_label, cat_features= cat_features)\n",
    "    test_pool = Pool(X_test_proc,label = test_label, cat_features= cat_features)\n",
    "\n",
    "    model_normal = CatBoostRegressor(iterations=500,\n",
    "                                 loss_function='SurvivalAft:dist=Normal',\n",
    "                                 eval_metric='SurvivalAft',\n",
    "                                 verbose=0\n",
    "                                )\n",
    "    _ = model_normal.fit(train_pool, eval_set=test_pool)\n",
    "    preds = model_normal.predict(test_pool, prediction_type='Exponent')\n",
    "    \n",
    "    return -preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ecc78",
   "metadata": {},
   "source": [
    "## Cross validation (8 fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "859d8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(preds, X_test, solution):\n",
    "    prediction= pd.DataFrame({\"ID\":X_test[\"ID\"], \"prediction\":preds})\n",
    "    sc_score = score(solution.copy(deep=True), prediction.copy(deep=True), \"ID\")\n",
    "    c_index = concordance_index(y_test['efs_time'], -preds, y_test['efs'])\n",
    "\n",
    "    return sc_score, c_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b61f5805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stratified c-index for fold 0: \n",
      "             SC-index: cph: 0.638669413508822, xgb_aft: 0.6426415841242906, cat_aft: 0.6503410301012419 \n",
      "             C_index: cph: 0.6698581672193501, xgb_aft: 0.6673489547220349, cat_aft: 0.6789335532832707 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "preproc_pipline = preproc_naive\n",
    "\n",
    "n_splits = 8\n",
    "kfold = KFold(n_splits = n_splits, shuffle = True, random_state = 42)\n",
    "target_features = ['efs', 'efs_time']\n",
    "\n",
    "for i, (train_idx,test_idx) in enumerate(kfold.split(df_train)):\n",
    "\n",
    "    X_train = df_train.iloc[train_idx].drop(columns = target_features)\n",
    "    y_train = df_train.loc[train_idx, target_features]\n",
    "\n",
    "    X_test = df_train.iloc[test_idx].drop(columns = target_features)\n",
    "    y_test = df_train.loc[test_idx, target_features]\n",
    "\n",
    "    preproc_pipline.fit(X_train)\n",
    "    X_train_preproc = preproc_pipline.transform(X_train)\n",
    "    X_test_preproc =preproc_pipline.transform(X_test)\n",
    "    \n",
    "    preds_cph = cph_model(X_train_preproc, y_train, X_test_preproc)\n",
    "    preds_xgb = xgb_aft_model(X_train_preproc, y_train, X_test_preproc, params = params)\n",
    "    preds_cb = cb_aft_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    solution = df_train.iloc[test_idx]\n",
    "    score_cph, c_index_cph = eval(preds_cph, X_test, solution)\n",
    "    score_xgb, c_index_xgb = eval(preds_xgb, X_test, solution)\n",
    "    score_cb, c_index_cb = eval(preds_cb, X_test, solution)\n",
    "\n",
    "    print(f\"stratified c-index for fold {i}: \\n \\\n",
    "            SC-index: cph: {score_cph}, xgb_aft: {score_xgb}, cat_aft: {score_cb} \\n \\\n",
    "            C_index: cph: {c_index_cph}, xgb_aft: {c_index_xgb}, cat_aft: {c_index_cb} \\n\")\n",
    "    if i == 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ab26728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stratified c-index for fold 0: \n",
      "             SC-index: cph: 0.6438916351249773, xgb_aft: 0.6399764018416064 \n",
      "             C_index: cph: 0.6719673825354888, xgb_aft: 0.665676503849992\n"
     ]
    }
   ],
   "source": [
    "preproc_pipline = preproc_sd\n",
    "\n",
    "n_splits = 8\n",
    "kfold = KFold(n_splits = n_splits, shuffle = True, random_state = 42)\n",
    "target_features = ['efs', 'efs_time']\n",
    "\n",
    "for i, (train_idx,test_idx) in enumerate(kfold.split(df_train)):\n",
    "\n",
    "    X_train = df_train.iloc[train_idx].drop(columns = target_features)\n",
    "    y_train = df_train.loc[train_idx, target_features]\n",
    "\n",
    "    X_test = df_train.iloc[test_idx].drop(columns = target_features)\n",
    "    y_test = df_train.loc[test_idx, target_features]\n",
    "\n",
    "    preproc_pipline.fit(X_train)\n",
    "    X_train_preproc = preproc_pipline.transform(X_train)\n",
    "    X_test_preproc =preproc_pipline.transform(X_test)\n",
    "    \n",
    "    preds_cph = cph_model(X_train_preproc, y_train, X_test_preproc)\n",
    "    preds_xgb = xgb_aft_model(X_train_preproc, y_train, X_test_preproc, params = params)\n",
    "\n",
    "    solution = df_train.iloc[test_idx]\n",
    "    score_cph, c_index_cph = eval(preds_cph, X_test, solution)\n",
    "    score_xgb, c_index_xgb = eval(preds_xgb, X_test, solution)\n",
    "\n",
    "    print(f\"stratified c-index for fold {i}: \\n \\\n",
    "            SC-index: cph: {score_cph}, xgb_aft: {score_xgb} \\n \\\n",
    "            C_index: cph: {c_index_cph}, xgb_aft: {c_index_xgb}\")\n",
    "    if i == 0: break\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boost_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
