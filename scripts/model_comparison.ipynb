{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b61e7cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main module is loaded\n",
      "/Users/chew/Desktop/CIBMTR_post_hct_survival/scripts/main_module.py\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import main_module as md\n",
    "\n",
    "# figure fonts configuration\n",
    "from matplotlib import rc\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7444601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import set_config\n",
    "\n",
    "from lifelines import CoxPHFitter\n",
    "# import the score function\n",
    "%run -i ../examples/concordance_index.ipynb\n",
    "\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.util import Surv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe1d6b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_val_test= pd.read_csv(\"../data/test_validation_set.csv\")\n",
    "df_val, df_test = train_test_split(df_val_test, train_size= 0.5, random_state = 41, shuffle = True)\n",
    "df_train = pd.read_csv(\"../data/train_set.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ba1f77",
   "metadata": {},
   "source": [
    "## Data preprocessing pipelines\n",
    "In this section, we create pipelines for preprocessing the data. The main goal here is to investigate if data imputation improves the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d114a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive preprocessor\n",
    "# replace missing categorical variables by 'missing', replace missing numerical values by -1\n",
    "class NaiveDataTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.columns = None\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transform = X.copy(deep = True)\n",
    "        cat_cols = X_transform.select_dtypes(include = 'O').columns\n",
    "        num_cols = X_transform.select_dtypes(exclude = 'O').columns\n",
    "        X_transform[cat_cols] = X_transform[cat_cols].fillna(\"missing\")\n",
    "        X_transform[num_cols] = X_transform[num_cols].fillna(-1.0)\n",
    "        return X_transform\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = X.columns\n",
    "        return self \n",
    "    \n",
    "    def get_feature_names_out(self, input_features = None):\n",
    "        return self.columns\n",
    "\n",
    "cat_cols = df_train.select_dtypes(include='O').columns\n",
    "num_cols = df_train.select_dtypes(exclude='O').columns.drop([\"ID\", 'year_hct','efs', 'efs_time'])\n",
    "other_cols = df_train.columns.drop([\"ID\", 'year_hct','efs', 'efs_time'])\n",
    "# set_config(transform_output=\"pandas\")\n",
    "preproc_naive = Pipeline(\n",
    "    steps = [('preprocessing',\n",
    "                ColumnTransformer([('naive_missing', NaiveDataTransformer(), other_cols),\n",
    "                                ('ID_year_dropper', 'drop', [\"ID\", 'year_hct'])],\n",
    "                                    sparse_threshold=0,\n",
    "                                    remainder='passthrough',\n",
    "                                    verbose_feature_names_out=False,\n",
    "                                    force_int_remainder_cols=False\n",
    "                                ).set_output(transform=\"pandas\")\n",
    "            ),\n",
    "            ('naive_one_hot_encode',\n",
    "                ColumnTransformer([('one_hot', OneHotEncoder(drop='first',\n",
    "                                                             min_frequency = 0.001,\n",
    "                                                             handle_unknown='ignore',\n",
    "                                                             sparse_output= False), cat_cols)],\n",
    "                                    sparse_threshold=0,\n",
    "                                    remainder='passthrough',\n",
    "                                    verbose_feature_names_out=False,\n",
    "                                    force_int_remainder_cols=False\n",
    "                                ).set_output(transform=\"pandas\")\n",
    "            )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5452c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing based on KNN imputation \n",
    "class MissingValueTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, null_list = [\"Missing Disease Status\", \"Missing disease status\"]):\n",
    "        self.null_list = null_list\n",
    "        self.columns = None\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transform = X.copy(deep = True)\n",
    "        X_transform.replace(self.null_list, np.nan, inplace = True)\n",
    "        return X_transform\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = X.columns\n",
    "        return self \n",
    "    \n",
    "    def get_feature_names_out(self, input_features = None):\n",
    "        return self.columns\n",
    "\n",
    "cat_cols = df_train.select_dtypes(include='O').columns\n",
    "preproc_sd = Pipeline(\n",
    "    [   \n",
    "        ('preprocessing',\n",
    "                ColumnTransformer([\n",
    "                                    ('cat_missing', MissingValueTransformer(), cat_cols),\n",
    "                                    ('ID_year_dropper', 'drop', [\"ID\", 'year_hct'])],\n",
    "                                    sparse_threshold=0,\n",
    "                                    remainder='passthrough',\n",
    "                                    verbose_feature_names_out=False,\n",
    "                                    force_int_remainder_cols=False\n",
    "                                ).set_output(transform=\"pandas\")\n",
    "        ),\n",
    "        (\n",
    "            \"encode_and_scale\",\n",
    "            ColumnTransformer(\n",
    "                [\n",
    "                    ('one_hot', \n",
    "                    OneHotEncoder(drop='first',\n",
    "                                    min_frequency = 0.001,\n",
    "                                    handle_unknown='ignore',\n",
    "                                    sparse_output= False\n",
    "                    ), \n",
    "                    cat_cols\n",
    "                    ),\n",
    "                    ('scale', StandardScaler(), ['donor_age', 'age_at_hct', 'karnofsky_score'])\n",
    "                ],\n",
    "                sparse_threshold=0,\n",
    "                remainder='passthrough',\n",
    "                verbose_feature_names_out=False,\n",
    "                force_int_remainder_cols=False\n",
    "            ).set_output(transform=\"pandas\")\n",
    "        ),\n",
    "        (\n",
    "            \"impute\",\n",
    "            KNNImputer().set_output(transform = \"pandas\")\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82651a10",
   "metadata": {},
   "source": [
    "## Modeling Method\n",
    "\n",
    "In this section, we implement the actual modeling methods including CPH model, XGboost AFT, and Catboost AFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "713d495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cph_model(X_train_preproc, y_train, X_test_preproc):\n",
    "\n",
    "    train_preproc = pd.concat([X_train_preproc, y_train], axis=1)\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(train_preproc, duration_col='efs_time', event_col='efs')\n",
    "    preds = cph.predict_partial_hazard(X_test_preproc)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9ddfc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGboost\n",
    "params = {'objective': 'survival:aft',\n",
    "          'eval_metric': 'aft-nloglik',\n",
    "          'aft_loss_distribution': 'normal',\n",
    "         'aft_loss_distribution_scale': 0.80,\n",
    "          'tree_method': 'hist', 'learning_rate': 0.05, 'max_depth': 6}\n",
    "   \n",
    "def xgb_aft_model(X_train_preproc, y_train, X_test_preproc, params = params):\n",
    "\n",
    "    # remove special character\n",
    "    X_train_preproc.columns = X_train_preproc.columns.str.replace('<','')\n",
    "    X_test_preproc.columns = X_test_preproc.columns.str.replace('<','')\n",
    "\n",
    "    y_lower_bound = y_train['efs_time'].copy(deep = True)\n",
    "    y_upper_bound = y_train['efs_time'].copy(deep = True)\n",
    "    y_upper_bound[y_train['efs'] == 0.0] = +np.inf\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train_preproc)\n",
    "    dtrain.set_float_info('label_lower_bound', y_lower_bound)\n",
    "    dtrain.set_float_info('label_upper_bound', y_upper_bound)\n",
    "\n",
    "    bst = xgb.train(params, dtrain, num_boost_round=500, evals=[(dtrain, 'train')], verbose_eval = 0)\n",
    "    dtest = xgb.DMatrix(X_test_preproc)\n",
    "    preds = bst.predict(dtest)\n",
    "\n",
    "    return -preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e7b7cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Catboost\n",
    "\n",
    "def cb_aft_model(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    # remove special character\n",
    "    nt = NaiveDataTransformer() \n",
    "    X_train_proc = nt.fit_transform(X_train)\n",
    "    X_test_proc = nt.fit_transform(X_test)\n",
    "\n",
    "    y_lower_train = y_train[['efs_time']].copy(deep = True)\n",
    "    y_upper_train = y_train[['efs_time']].copy(deep = True)\n",
    "    # in catboost, infinity is represented by -1\n",
    "    y_upper_train.iloc[y_train['efs'] == 0.0] = -1\n",
    "    train_label = np.concatenate((y_lower_train, y_upper_train), axis = 1)\n",
    "    train_label = pd.DataFrame(train_label, columns = ['y_lower_train', 'y_upper_train'])\n",
    "    cat_features = list(X_train.select_dtypes(include= 'O').columns)\n",
    "\n",
    "    y_lower_test = y_test[['efs_time']].copy(deep = True)\n",
    "    y_upper_test = y_test[['efs_time']].copy(deep = True)\n",
    "    # in catboost, infinity is represented by -1\n",
    "    y_upper_test.iloc[y_test['efs'] == 0.0] = -1\n",
    "    test_label = np.concatenate((y_lower_test, y_upper_test), axis = 1)\n",
    "    test_label = pd.DataFrame(test_label, columns = ['y_lower_test', 'y_upper_test'])\n",
    "\n",
    "    train_pool = Pool(X_train_proc,label = train_label, cat_features= cat_features)\n",
    "    test_pool = Pool(X_test_proc,label = test_label, cat_features= cat_features)\n",
    "\n",
    "    model_normal = CatBoostRegressor(iterations=500,\n",
    "                                 loss_function='SurvivalAft:dist=Normal',\n",
    "                                 eval_metric='SurvivalAft',\n",
    "                                 verbose=0\n",
    "                                )\n",
    "    _ = model_normal.fit(train_pool, eval_set=test_pool)\n",
    "    preds = model_normal.predict(test_pool, prediction_type='Exponent')\n",
    "    \n",
    "    return -preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0b409d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random survival forest\n",
    "def rsf_model(X_train_preproc, y_train, X_test_preproc):\n",
    "\n",
    "    y_train = Surv.from_dataframe(\"efs\", \"efs_time\", y_train)\n",
    "\n",
    "    rsf = RandomSurvivalForest(\n",
    "        n_estimators=30,\n",
    "        max_depth=10,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        n_jobs=4,\n",
    "        verbose=1,\n",
    "        random_state=42\n",
    "    )\n",
    "    rsf.fit(X_train_preproc, y_train)\n",
    "    surv_funcs = rsf.predict_survival_function(X_test_preproc, return_array=False)\n",
    "    preds = np.array([-np.trapz(fn.y, fn.x) for fn in surv_funcs])\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "700e40e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hybrid cph\n",
    "\n",
    "def hybrid_cph_model(X_train_preproc, y_train, X_test_preproc):\n",
    "\n",
    "    # create embedding with logistic regression\n",
    "    train_idx = X_train_preproc.index\n",
    "    test_idx = X_test_preproc.index\n",
    "    col = X_train_preproc.columns.to_list()\n",
    "    col.append(\"class\")\n",
    "    clf = LogisticRegression(max_iter=15000)\n",
    "    clf.fit(X_train_preproc, y_train[\"efs\"])\n",
    "    X_train_preproc = pd.DataFrame(data = np.concatenate((X_train_preproc.to_numpy(), np.reshape(clf.predict(X_train_preproc), (-1, 1) )), axis=1), \n",
    "                                   index = train_idx,\n",
    "                                   columns = col)\n",
    "\n",
    "    X_test_preproc = pd.DataFrame(data = np.concatenate((X_test_preproc.to_numpy(), np.reshape(clf.predict(X_test_preproc), (-1, 1) )), axis=1), \n",
    "                                  index = test_idx,\n",
    "                                  columns = col)\n",
    "\n",
    "    # train cph\n",
    "    train_preproc = pd.concat([X_train_preproc, y_train], axis=1)\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(train_preproc, duration_col='efs_time', event_col='efs')\n",
    "    preds = cph.predict_partial_hazard(X_test_preproc)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7329eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hybrid XGboost\n",
    "\n",
    "params = {'objective': 'survival:aft',\n",
    "          'eval_metric': 'aft-nloglik',\n",
    "          'aft_loss_distribution': 'normal',\n",
    "         'aft_loss_distribution_scale': 0.80,\n",
    "          'tree_method': 'hist', 'learning_rate': 0.05, 'max_depth': 6}\n",
    "   \n",
    "def hybrid_xgb_aft_model(X_train_preproc, y_train, X_test_preproc, params = params):\n",
    "\n",
    "    # create embedding with logistic regression\n",
    "    train_idx = X_train_preproc.index\n",
    "    test_idx = X_test_preproc.index\n",
    "    col = X_train_preproc.columns.to_list()\n",
    "    col.append(\"class\")\n",
    "    clf = LogisticRegression(max_iter=15000)\n",
    "    clf.fit(X_train_preproc, y_train[\"efs\"])\n",
    "    X_train_preproc = pd.DataFrame(data = np.concatenate((X_train_preproc.to_numpy(), np.reshape(clf.predict(X_train_preproc), (-1, 1) )), axis=1), \n",
    "                                   index = train_idx,\n",
    "                                   columns = col)\n",
    "\n",
    "    X_test_preproc = pd.DataFrame(data = np.concatenate((X_test_preproc.to_numpy(), np.reshape(clf.predict(X_test_preproc), (-1, 1) )), axis=1), \n",
    "                                  index = test_idx,\n",
    "                                  columns = col)\n",
    "\n",
    "    # train XGboost\n",
    "    # remove special character\n",
    "    X_train_preproc.columns = X_train_preproc.columns.str.replace('<','')\n",
    "    X_test_preproc.columns = X_test_preproc.columns.str.replace('<','')\n",
    "\n",
    "    y_lower_bound = y_train['efs_time'].copy(deep = True)\n",
    "    y_upper_bound = y_train['efs_time'].copy(deep = True)\n",
    "    y_upper_bound[y_train['efs'] == 0.0] = +np.inf\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train_preproc)\n",
    "    dtrain.set_float_info('label_lower_bound', y_lower_bound)\n",
    "    dtrain.set_float_info('label_upper_bound', y_upper_bound)\n",
    "\n",
    "    bst = xgb.train(params, dtrain, num_boost_round=500, evals=[(dtrain, 'train')], verbose_eval = 0)\n",
    "    dtest = xgb.DMatrix(X_test_preproc)\n",
    "    preds = bst.predict(dtest)\n",
    "\n",
    "    return -preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e63ab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hybrid random survival forest\n",
    "\n",
    "def hybrid_rsf_model(X_train_preproc, y_train, X_test_preproc):\n",
    "\n",
    "    # create embedding with logistic regression\n",
    "    train_idx = X_train_preproc.index\n",
    "    test_idx = X_test_preproc.index\n",
    "    col = X_train_preproc.columns.to_list()\n",
    "    col.append(\"class\")\n",
    "    clf = LogisticRegression(max_iter=15000)\n",
    "    clf.fit(X_train_preproc, y_train[\"efs\"])\n",
    "    X_train_preproc = pd.DataFrame(data = np.concatenate((X_train_preproc.to_numpy(), np.reshape(clf.predict(X_train_preproc), (-1, 1) )), axis=1), \n",
    "                                   index = train_idx,\n",
    "                                   columns = col)\n",
    "\n",
    "    X_test_preproc = pd.DataFrame(data = np.concatenate((X_test_preproc.to_numpy(), np.reshape(clf.predict(X_test_preproc), (-1, 1) )), axis=1), \n",
    "                                  index = test_idx,\n",
    "                                  columns = col)\n",
    "\n",
    "    # train random survival forest\n",
    "    y_train = Surv.from_dataframe(\"efs\", \"efs_time\", y_train)\n",
    "\n",
    "    rsf = RandomSurvivalForest(\n",
    "        n_estimators=30,\n",
    "        max_depth=10,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        n_jobs=4,\n",
    "        verbose=1,\n",
    "        random_state=42\n",
    "    )\n",
    "    rsf.fit(X_train_preproc, y_train)\n",
    "    surv_funcs = rsf.predict_survival_function(X_test_preproc, return_array=False)\n",
    "    preds = np.array([-np.trapz(fn.y, fn.x) for fn in surv_funcs])\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ecc78",
   "metadata": {},
   "source": [
    "## Cross validation (8 fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "859d8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(preds, X_test, solution):\n",
    "    prediction= pd.DataFrame({\"ID\":X_test[\"ID\"], \"prediction\":preds})\n",
    "    sc_score = score(solution.copy(deep=True), prediction.copy(deep=True), \"ID\")\n",
    "    c_index = concordance_index(y_test['efs_time'], -preds, y_test['efs'])\n",
    "\n",
    "    return sc_score, c_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b61f5805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:   14.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:    8.3s finished\n",
      "/tmp/ipykernel_33435/3339955221.py:17: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  preds = np.array([-np.trapz(fn.y, fn.x) for fn in surv_funcs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stratified c-index for fold 0: \n",
      "             SC-index: cph: 0.638669413508822, xgb_aft: 0.6426415841242906, cat_aft: 0.6503410301012419, rsf_aft: 0.6177788760700511 \n",
      "             C_index: cph: 0.6698581672193501, xgb_aft: 0.6673489547220349, cat_aft: 0.6789335532832707, rsf_aft: 0.6512594472716087 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "preproc_pipline = preproc_naive\n",
    "\n",
    "n_splits = 8\n",
    "kfold = KFold(n_splits = n_splits, shuffle = True, random_state = 42)\n",
    "target_features = ['efs', 'efs_time']\n",
    "\n",
    "for i, (train_idx,test_idx) in enumerate(kfold.split(df_train)):\n",
    "\n",
    "    X_train = df_train.iloc[train_idx].drop(columns = target_features)\n",
    "    y_train = df_train.loc[train_idx, target_features]\n",
    "\n",
    "    X_test = df_train.iloc[test_idx].drop(columns = target_features)\n",
    "    y_test = df_train.loc[test_idx, target_features]\n",
    "\n",
    "    preproc_pipline.fit(X_train)\n",
    "    X_train_preproc = preproc_pipline.transform(X_train)\n",
    "    X_test_preproc =preproc_pipline.transform(X_test)\n",
    "    \n",
    "    preds_cph = cph_model(X_train_preproc, y_train, X_test_preproc)\n",
    "    preds_xgb = xgb_aft_model(X_train_preproc, y_train, X_test_preproc, params = params)\n",
    "    preds_cb = cb_aft_model(X_train, y_train, X_test, y_test)\n",
    "    preds_rsf = rsf_model(X_train_preproc, y_train, X_test_preproc)\n",
    "\n",
    "    solution = df_train.iloc[test_idx]\n",
    "    score_cph, c_index_cph = eval(preds_cph, X_test, solution)\n",
    "    score_xgb, c_index_xgb = eval(preds_xgb, X_test, solution)\n",
    "    score_cb, c_index_cb = eval(preds_cb, X_test, solution)\n",
    "    score_rsf, c_index_rsf = eval(preds_rsf, X_test, solution)\n",
    "\n",
    "    print(f\"stratified c-index for fold {i}: \\n \\\n",
    "            SC-index: cph: {score_cph}, xgb_aft: {score_xgb}, cat_aft: {score_cb}, rsf_aft: {score_rsf} \\n \\\n",
    "            C_index: cph: {c_index_cph}, xgb_aft: {c_index_xgb}, cat_aft: {c_index_cb}, rsf_aft: {c_index_rsf} \\n\")\n",
    "    if i == 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ab26728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:   11.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:    7.7s finished\n",
      "/var/folders/89/cmkxgs714ss6xl1nw7t10x3c0000gn/T/ipykernel_891/3339955221.py:17: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  preds = np.array([-np.trapz(fn.y, fn.x) for fn in surv_funcs])\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:   11.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:    7.6s finished\n",
      "/var/folders/89/cmkxgs714ss6xl1nw7t10x3c0000gn/T/ipykernel_891/1208107843.py:34: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  preds = np.array([-np.trapz(fn.y, fn.x) for fn in surv_funcs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stratified c-index for fold 0: \n",
      "             SC-index: cph: 0.6438916351249773, xgb_aft: 0.6399764018416064, rsf_aft: 0.6151926975121839, hcph: 0.6442449886247044, hxgb_aft: 0.6392242183910994, hrsf_aft: 0.6225285349015262 \n",
      "             C_index: cph: 0.6719673825354888, xgb_aft: 0.665676503849992, rsf_aft: 0.6497581173690695, hcph: 0.6720966807434218, hxgb_aft: 0.6650820997661295, hrsf_aft: 0.6563452789149246\n"
     ]
    }
   ],
   "source": [
    "preproc_pipline = preproc_sd\n",
    "\n",
    "n_splits = 8\n",
    "kfold = KFold(n_splits = n_splits, shuffle = True, random_state = 42)\n",
    "target_features = ['efs', 'efs_time']\n",
    "\n",
    "for i, (train_idx,test_idx) in enumerate(kfold.split(df_train)):\n",
    "\n",
    "    X_train = df_train.iloc[train_idx].drop(columns = target_features)\n",
    "    y_train = df_train.loc[train_idx, target_features]\n",
    "\n",
    "    X_test = df_train.iloc[test_idx].drop(columns = target_features)\n",
    "    y_test = df_train.loc[test_idx, target_features]\n",
    "\n",
    "    preproc_pipline.fit(X_train)\n",
    "    X_train_preproc = preproc_pipline.transform(X_train)\n",
    "    X_test_preproc =preproc_pipline.transform(X_test)\n",
    "    \n",
    "    preds_cph = cph_model(X_train_preproc, y_train, X_test_preproc)\n",
    "    preds_xgb = xgb_aft_model(X_train_preproc, y_train, X_test_preproc, params = params)\n",
    "    preds_rsf = rsf_model(X_train_preproc, y_train, X_test_preproc)\n",
    "    preds_hcph = hybrid_cph_model(X_train_preproc, y_train, X_test_preproc)\n",
    "    preds_hxgb = hybrid_xgb_aft_model(X_train_preproc, y_train, X_test_preproc)\n",
    "    preds_hrsf = hybrid_rsf_model(X_train_preproc, y_train, X_test_preproc)\n",
    "\n",
    "    solution = df_train.iloc[test_idx]\n",
    "    score_cph, c_index_cph = eval(preds_cph, X_test, solution)\n",
    "    score_xgb, c_index_xgb = eval(preds_xgb, X_test, solution)\n",
    "    score_rsf, c_index_rsf = eval(preds_rsf, X_test, solution)\n",
    "    score_hcph, c_index_hcph = eval(preds_hcph, X_test, solution)\n",
    "    score_hxgb, c_index_hxgb = eval(preds_hxgb, X_test, solution)\n",
    "    score_hrsf, c_index_hrsf = eval(preds_hrsf, X_test, solution)\n",
    "\n",
    "    print(f\"stratified c-index for fold {i}: \\n \\\n",
    "            SC-index: cph: {score_cph}, xgb_aft: {score_xgb}, rsf_aft: {score_rsf}, hcph: {score_hcph}, hxgb_aft: {score_hxgb}, hrsf_aft: {score_hrsf} \\n \\\n",
    "            C_index: cph: {c_index_cph}, xgb_aft: {c_index_xgb}, rsf_aft: {c_index_rsf}, hcph: {c_index_hcph}, hxgb_aft: {c_index_hxgb}, hrsf_aft: {c_index_hrsf}\")\n",
    "    if i == 0: break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
