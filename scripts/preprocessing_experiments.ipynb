{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import main_module as md\n",
    "\n",
    "# figure fonts configuration\n",
    "from matplotlib import rc\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training set and validation set\n",
    "df_val_test= pd.read_csv(\"../data/test_validation_set.csv\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_val, df_test = train_test_split(df_val_test, train_size= 0.5, random_state = 41, shuffle = True)\n",
    "df_train = pd.read_csv(\"../data/train_set.csv\")\n",
    "\n",
    "\n",
    "hct_df = md.hct(\"../data/train_set.csv\")\n",
    "hct_df.data = hct_df.clean(method=\"replace\", params=\\\n",
    "                          [[\"Not done\", \"Not tested\", \"Other\", \"Missing disease status\", \"Non-resident of the U.S.\"], \\\n",
    "                           'missing_cat'])\n",
    "# hct_df.report_missing_values(hct_df.data[hct_df.data.select_dtypes(include=(\"float64\")).columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import KNNImputer, IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import set_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Careful designed preprocessor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingIndicateTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, null_list = [\"Not done\", \"Not tested\", \"Other\", \"Missing disease status\", \"Non-resident of the U.S.\"]):\n",
    "        self.null_list = null_list\n",
    "        self.columns = None\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transform = X.copy(deep = True)\n",
    "        X_transform.replace(self.null_list, \"missing\", inplace = True)\n",
    "        cat_cols = X_transform.select_dtypes(include = 'O').columns\n",
    "        X_transform[cat_cols] = X_transform[cat_cols].fillna(\"missing\")\n",
    "        return X_transform\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = X.columns\n",
    "        return self \n",
    "    \n",
    "    def get_feature_names_out(self, input_features = None):\n",
    "        return self.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df_train.select_dtypes(include='O').columns\n",
    "num_cols = df_train.select_dtypes(exclude='O').columns.drop([\"ID\", 'year_hct','efs', 'efs_time'])\n",
    "\n",
    "# set_config(transform_output=\"pandas\")\n",
    "preproc = Pipeline(\n",
    "    steps = [('preprocessing',\n",
    "                ColumnTransformer([('cat_missing', MissingIndicateTransformer(), cat_cols),\n",
    "                                ('ID_year_dropper', 'drop', [\"ID\", 'year_hct']),\n",
    "                                ('scale', StandardScaler(), num_cols)],\n",
    "                                    sparse_threshold=0,\n",
    "                                    remainder='passthrough',\n",
    "                                    verbose_feature_names_out=False,\n",
    "                                    force_int_remainder_cols=False\n",
    "                                ).set_output(transform=\"pandas\")\n",
    "            ),\n",
    "            ('one_hot_encode_and_impute',\n",
    "                ColumnTransformer([('one_hot', OneHotEncoder(drop='first',\n",
    "                                                             min_frequency = 0.001,\n",
    "                                                             handle_unknown='ignore',\n",
    "                                                             sparse_output= False), cat_cols),\n",
    "                                ('impute_donor_age', SimpleImputer(strategy=\"median\"), ['donor_age']),\n",
    "                                ('impute_other', KNNImputer(n_neighbors=5), num_cols.drop(['donor_age']))],\n",
    "                                    sparse_threshold=0,\n",
    "                                    remainder='passthrough',\n",
    "                                    verbose_feature_names_out=False,\n",
    "                                    force_int_remainder_cols=False\n",
    "                                ).set_output(transform=\"pandas\")\n",
    "            )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc.fit(df_train)\n",
    "df_train_preproc = preproc.transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dri_score_High - TED AML case &lt;missing cytogenetics</th>\n",
       "      <th>dri_score_Intermediate</th>\n",
       "      <th>dri_score_Intermediate - TED AML case &lt;missing cytogenetics</th>\n",
       "      <th>dri_score_Low</th>\n",
       "      <th>dri_score_N/A - disease not classifiable</th>\n",
       "      <th>dri_score_N/A - non-malignant indication</th>\n",
       "      <th>dri_score_N/A - pediatric</th>\n",
       "      <th>dri_score_TBD cytogenetics</th>\n",
       "      <th>dri_score_Very high</th>\n",
       "      <th>dri_score_missing</th>\n",
       "      <th>...</th>\n",
       "      <th>age_at_hct</th>\n",
       "      <th>hla_match_a_low</th>\n",
       "      <th>hla_match_b_high</th>\n",
       "      <th>comorbidity_score</th>\n",
       "      <th>karnofsky_score</th>\n",
       "      <th>hla_low_res_8</th>\n",
       "      <th>hla_match_drb1_high</th>\n",
       "      <th>hla_low_res_10</th>\n",
       "      <th>efs</th>\n",
       "      <th>efs_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.630684</td>\n",
       "      <td>0.635095</td>\n",
       "      <td>-1.499348</td>\n",
       "      <td>-0.853537</td>\n",
       "      <td>0.557682</td>\n",
       "      <td>-1.214733</td>\n",
       "      <td>-1.535178</td>\n",
       "      <td>-0.882139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558801</td>\n",
       "      <td>0.635095</td>\n",
       "      <td>0.647705</td>\n",
       "      <td>0.146609</td>\n",
       "      <td>-2.168356</td>\n",
       "      <td>0.700292</td>\n",
       "      <td>0.635422</td>\n",
       "      <td>0.708859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.229453</td>\n",
       "      <td>0.635095</td>\n",
       "      <td>0.647705</td>\n",
       "      <td>1.146755</td>\n",
       "      <td>0.557682</td>\n",
       "      <td>0.700292</td>\n",
       "      <td>0.635422</td>\n",
       "      <td>0.708859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.833060</td>\n",
       "      <td>0.635095</td>\n",
       "      <td>0.647705</td>\n",
       "      <td>-0.853537</td>\n",
       "      <td>0.557682</td>\n",
       "      <td>0.700292</td>\n",
       "      <td>0.635422</td>\n",
       "      <td>0.708859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.638944</td>\n",
       "      <td>0.635095</td>\n",
       "      <td>0.647705</td>\n",
       "      <td>-0.853537</td>\n",
       "      <td>-0.350997</td>\n",
       "      <td>0.700292</td>\n",
       "      <td>0.635422</td>\n",
       "      <td>0.708859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dri_score_High - TED AML case <missing cytogenetics  \\\n",
       "0                                                0.0     \n",
       "1                                                0.0     \n",
       "2                                                0.0     \n",
       "3                                                1.0     \n",
       "4                                                0.0     \n",
       "\n",
       "   dri_score_Intermediate  \\\n",
       "0                     1.0   \n",
       "1                     1.0   \n",
       "2                     0.0   \n",
       "3                     0.0   \n",
       "4                     0.0   \n",
       "\n",
       "   dri_score_Intermediate - TED AML case <missing cytogenetics  dri_score_Low  \\\n",
       "0                                                0.0                      0.0   \n",
       "1                                                0.0                      0.0   \n",
       "2                                                0.0                      0.0   \n",
       "3                                                0.0                      0.0   \n",
       "4                                                0.0                      0.0   \n",
       "\n",
       "   dri_score_N/A - disease not classifiable  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "\n",
       "   dri_score_N/A - non-malignant indication  dri_score_N/A - pediatric  \\\n",
       "0                                       0.0                        0.0   \n",
       "1                                       0.0                        0.0   \n",
       "2                                       0.0                        0.0   \n",
       "3                                       0.0                        0.0   \n",
       "4                                       0.0                        0.0   \n",
       "\n",
       "   dri_score_TBD cytogenetics  dri_score_Very high  dri_score_missing  ...  \\\n",
       "0                         0.0                  0.0                0.0  ...   \n",
       "1                         0.0                  0.0                0.0  ...   \n",
       "2                         0.0                  0.0                0.0  ...   \n",
       "3                         0.0                  0.0                0.0  ...   \n",
       "4                         1.0                  0.0                0.0  ...   \n",
       "\n",
       "   age_at_hct  hla_match_a_low  hla_match_b_high  comorbidity_score  \\\n",
       "0    0.630684         0.635095         -1.499348          -0.853537   \n",
       "1    0.558801         0.635095          0.647705           0.146609   \n",
       "2    1.229453         0.635095          0.647705           1.146755   \n",
       "3   -1.833060         0.635095          0.647705          -0.853537   \n",
       "4   -1.638944         0.635095          0.647705          -0.853537   \n",
       "\n",
       "   karnofsky_score  hla_low_res_8  hla_match_drb1_high  hla_low_res_10  efs  \\\n",
       "0         0.557682      -1.214733            -1.535178       -0.882139  0.0   \n",
       "1        -2.168356       0.700292             0.635422        0.708859  1.0   \n",
       "2         0.557682       0.700292             0.635422        0.708859  0.0   \n",
       "3         0.557682       0.700292             0.635422        0.708859  0.0   \n",
       "4        -0.350997       0.700292             0.635422        0.708859  1.0   \n",
       "\n",
       "   efs_time  \n",
       "0    93.779  \n",
       "1    12.088  \n",
       "2    25.724  \n",
       "3    43.373  \n",
       "4     8.593  \n",
       "\n",
       "[5 rows x 160 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = pd.DataFrame(df_train_ready, columns=one_hot_impute.get_feature_names_out())\n",
    "df_train_preproc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Percentage Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dri_score_High - TED AML case &lt;missing cytogen...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dri_score_Intermediate</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dri_score_Intermediate - TED AML case &lt;missing...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dri_score_Low</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dri_score_N/A - disease not classifiable</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>hla_low_res_8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>hla_match_drb1_high</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>hla_low_res_10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>efs</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>efs_time</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Feature  Percentage Missing\n",
       "0    dri_score_High - TED AML case <missing cytogen...                 0.0\n",
       "1                               dri_score_Intermediate                 0.0\n",
       "2    dri_score_Intermediate - TED AML case <missing...                 0.0\n",
       "3                                        dri_score_Low                 0.0\n",
       "4             dri_score_N/A - disease not classifiable                 0.0\n",
       "..                                                 ...                 ...\n",
       "155                                      hla_low_res_8                 0.0\n",
       "156                                hla_match_drb1_high                 0.0\n",
       "157                                     hla_low_res_10                 0.0\n",
       "158                                                efs                 0.0\n",
       "159                                           efs_time                 0.0\n",
       "\n",
       "[160 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hct_df.report_missing_values(df_train_preproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kfold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import CoxPHFitter\n",
    "# import the score function\n",
    "%run -i ../examples/concordance_index.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rzhang98\\miniconda3\\envs\\erdo_sp25_post_hct\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:246: UserWarning: Found unknown categories in columns [25] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "n_splits = 10\n",
    "kfold = KFold(n_splits = n_splits, shuffle = True, random_state = 42)\n",
    "c_indexes = np.zeros(n_splits)\n",
    "scores = np.zeros(n_splits)\n",
    "target_features = ['efs', 'efs_time']\n",
    "\n",
    "for i, (train_idx,test_idx) in enumerate(kfold.split(df_train)):\n",
    "\n",
    "    X_train = df_train.iloc[train_idx].drop(columns = target_features)\n",
    "    y_train = df_train.loc[train_idx, target_features]\n",
    "\n",
    "    X_test = df_train.iloc[test_idx].drop(columns = target_features)\n",
    "    y_test = df_train.loc[test_idx, target_features]\n",
    "\n",
    "    preproc.fit(X_train)\n",
    "    X_train_preproc = preproc.transform(X_train)\n",
    "    X_test_preproc =preproc.transform(X_test)\n",
    "\n",
    "    train_preproc = pd.concat([X_train_preproc, y_train], axis=1)\n",
    "    test_preproc = pd.concat([X_test_preproc, y_test], axis=1)\n",
    "\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(train_preproc, duration_col='efs_time', event_col='efs')\n",
    "    preds = cph.predict_partial_hazard(X_test_preproc)\n",
    "\n",
    "    solution = df_train.iloc[test_idx]\n",
    "    prediction = pd.DataFrame({\"ID\":X_test[\"ID\"], \"prediction\":preds})\n",
    "    scores[i] = score(solution.copy(deep=True), prediction.copy(deep=True), \"ID\")\n",
    "    c_indexes[i] = concordance_index(y_test['efs_time'], -preds, y_test['efs'])\n",
    "# 27m 56.2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stratified c-index: \n",
      " [0.647206   0.65912036 0.65153799 0.63008074 0.64940412 0.66133796\n",
      " 0.65071265 0.63895584 0.65555021 0.64092212] \n",
      ", c-index: \n",
      " [0.67327646 0.67850871 0.6711965  0.66579483 0.67326945 0.67590336\n",
      " 0.66382557 0.65796142 0.67129549 0.66691247]\n"
     ]
    }
   ],
   "source": [
    "print(f\"stratified c-index: \\n {scores} \\n, c-index: \\n {c_indexes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive preprocessor\n",
    "# replace missing categorical variables by 'missing', replace missing numerical values by -1\n",
    "class NaiveDataTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.columns = None\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transform = X.copy(deep = True)\n",
    "        cat_cols = X_transform.select_dtypes(include = 'O').columns\n",
    "        num_cols = X_transform.select_dtypes(exclude = 'O').columns\n",
    "        X_transform[cat_cols] = X_transform[cat_cols].fillna(\"missing\")\n",
    "        X_transform[num_cols] = X_transform[num_cols].fillna(-1.0)\n",
    "        return X_transform\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = X.columns\n",
    "        return self \n",
    "    \n",
    "    def get_feature_names_out(self, input_features = None):\n",
    "        return self.columns\n",
    "\n",
    "cat_cols = df_train.select_dtypes(include='O').columns\n",
    "num_cols = df_train.select_dtypes(exclude='O').columns.drop([\"ID\", 'year_hct','efs', 'efs_time'])\n",
    "other_cols = df_train.columns.drop([\"ID\", 'year_hct','efs', 'efs_time'])\n",
    "# set_config(transform_output=\"pandas\")\n",
    "preproc_naive = Pipeline(\n",
    "    steps = [('preprocessing',\n",
    "                ColumnTransformer([('naive_missing', NaiveDataTransformer(), other_cols),\n",
    "                                ('ID_year_dropper', 'drop', [\"ID\", 'year_hct'])],\n",
    "                                    sparse_threshold=0,\n",
    "                                    remainder='passthrough',\n",
    "                                    verbose_feature_names_out=False,\n",
    "                                    force_int_remainder_cols=False\n",
    "                                ).set_output(transform=\"pandas\")\n",
    "            ),\n",
    "            ('naive_one_hot_encode',\n",
    "                ColumnTransformer([('one_hot', OneHotEncoder(drop='first',\n",
    "                                                             min_frequency = 0.001,\n",
    "                                                             handle_unknown='ignore',\n",
    "                                                             sparse_output= False), cat_cols)],\n",
    "                                    sparse_threshold=0,\n",
    "                                    remainder='passthrough',\n",
    "                                    verbose_feature_names_out=False,\n",
    "                                    force_int_remainder_cols=False\n",
    "                                ).set_output(transform=\"pandas\")\n",
    "            )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocecss with interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with all zeros\n",
    "class LowVarDropTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.columns = None\n",
    "        self.low_var_cols = None\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transform = X.copy(deep = True)\n",
    "        X_transform.drop(columns = self.low_var_cols, inplace=True)\n",
    "        return X_transform\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.low_var_cols = X.columns[X.var() < 0.2]\n",
    "        self.columns = X.columns.drop(self.low_var_cols)\n",
    "        return self \n",
    "    \n",
    "    def get_feature_names_out(self, input_features = None):\n",
    "        return self.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "cat_cols = df_train.select_dtypes(include='O').columns\n",
    "num_cols = df_train.select_dtypes(exclude='O').columns.drop([\"ID\", 'year_hct','efs', 'efs_time'])\n",
    "other_cols = df_train.columns.drop([\"ID\", 'year_hct','efs', 'efs_time'])\n",
    "preproc_interact = Pipeline(\n",
    "    steps = [('preprocessing',\n",
    "                ColumnTransformer([('naive_missing', NaiveDataTransformer(), other_cols),\n",
    "                                ('ID_year_dropper', 'drop', [\"ID\", 'year_hct'])],\n",
    "                                    sparse_threshold=0,\n",
    "                                    remainder='passthrough',\n",
    "                                    verbose_feature_names_out=False,\n",
    "                                    force_int_remainder_cols=False\n",
    "                                ).set_output(transform=\"pandas\")\n",
    "            ),\n",
    "            ('naive_one_hot_encode',\n",
    "                ColumnTransformer([('one_hot', OneHotEncoder(drop='first',\n",
    "                                                             min_frequency = 0.001,\n",
    "                                                             handle_unknown='ignore',\n",
    "                                                             sparse_output= False), cat_cols),\n",
    "                                    ('scale', StandardScaler(), num_cols)],\n",
    "                                    sparse_threshold=0,\n",
    "                                    remainder='passthrough',\n",
    "                                    verbose_feature_names_out=False,\n",
    "                                    force_int_remainder_cols=False\n",
    "                                ).set_output(transform=\"pandas\")\n",
    "            ),\n",
    "            ('add_interaction',\n",
    "                PolynomialFeatures(2, interaction_only=True, include_bias=False).set_output(transform = \"pandas\")\n",
    "            ),\n",
    "            ('drop_low_variance_columns', LowVarDropTransformer().set_output(transform=\"pandas\"))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPH: test and validation Stratified C-index preformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cph_report(df_train, df_test, pipeline, penalizer = 0.0, l1_ratio = 0.0):\n",
    "    target_features = ['efs', 'efs_time']\n",
    "    X_train = df_train.drop(columns = target_features)\n",
    "    y_train = df_train[target_features]\n",
    "\n",
    "    X_test = df_test.drop(columns= target_features)\n",
    "    y_test = df_test[target_features]\n",
    "\n",
    "    pipeline.fit(X_train)\n",
    "    X_train_preproc = pipeline.transform(X_train)\n",
    "    X_test_preproc = pipeline.transform(X_test)\n",
    "\n",
    "    train_preproc = pd.concat([X_train_preproc, y_train], axis=1)\n",
    "    test_preproc = pd.concat([X_test_preproc, y_test], axis=1)\n",
    "\n",
    "    cph = CoxPHFitter(penalizer = penalizer, l1_ratio= l1_ratio)\n",
    "    cph.fit(train_preproc, duration_col='efs_time', event_col='efs')\n",
    "    preds = cph.predict_partial_hazard(X_test_preproc)\n",
    "\n",
    "    solution = df_test\n",
    "    prediction = pd.DataFrame({\"ID\":X_test[\"ID\"], \"prediction\":preds})\n",
    "    test_SCIndex = score(solution.copy(deep=True), prediction.copy(deep=True), \"ID\")\n",
    "    test_C_index = concordance_index(y_test['efs_time'], -preds, y_test['efs'])\n",
    "    print(f\"        stratified c-index: {test_SCIndex}, c-index: {test_C_index}\")\n",
    "\n",
    "    return test_SCIndex, test_C_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preformance of the naive preprocessor:\n",
      "    performance on the validation set with penalizer 0.0, l1_ratio 0.0:\n",
      "        stratified c-index: 0.6534229834010374, c-index: 0.6708225220550078\n",
      "    performance on the validation set with penalizer 0.0, l1_ratio 0.2:\n",
      "        stratified c-index: 0.6534229834010374, c-index: 0.6708225220550078\n",
      "    performance on the validation set with penalizer 0.0, l1_ratio 0.5:\n",
      "        stratified c-index: 0.6534229834010374, c-index: 0.6708225220550078\n",
      "    performance on the validation set with penalizer 0.0, l1_ratio 0.8:\n",
      "        stratified c-index: 0.6534229834010374, c-index: 0.6708225220550078\n",
      "    performance on the validation set with penalizer 0.01, l1_ratio 0.0:\n",
      "        stratified c-index: 0.6535804328851086, c-index: 0.6712052413077322\n",
      "    performance on the validation set with penalizer 0.01, l1_ratio 0.2:\n",
      "        stratified c-index: 0.6549412042902181, c-index: 0.6722267526626634\n",
      "    performance on the validation set with penalizer 0.01, l1_ratio 0.5:\n",
      "        stratified c-index: 0.6542007970906663, c-index: 0.671586107198458\n",
      "    performance on the validation set with penalizer 0.01, l1_ratio 0.8:\n",
      "        stratified c-index: 0.6525915739144226, c-index: 0.6696888822991574\n",
      "    performance on the validation set with penalizer 0.2, l1_ratio 0.0:\n",
      "        stratified c-index: 0.649671473928392, c-index: 0.6673854622284825\n",
      "    performance on the validation set with penalizer 0.2, l1_ratio 0.2:\n",
      "        stratified c-index: 0.6203423638685748, c-index: 0.6417284453999555\n",
      "    performance on the validation set with penalizer 0.2, l1_ratio 0.5:\n",
      "        stratified c-index: 0.5955934954973761, c-index: 0.6184647366990387\n",
      "    performance on the validation set with penalizer 0.2, l1_ratio 0.8:\n",
      "        stratified c-index: 0.6175441982409653, c-index: 0.6379587070946697\n",
      "    performance on the validation set with penalizer 0.5, l1_ratio 0.0:\n",
      "        stratified c-index: 0.6441043761341496, c-index: 0.6624357501173795\n",
      "    performance on the validation set with penalizer 0.5, l1_ratio 0.2:\n",
      "        stratified c-index: 0.5979062654476677, c-index: 0.6205596535448638\n",
      "    performance on the validation set with penalizer 0.5, l1_ratio 0.5:\n",
      "        stratified c-index: 0.6157007626214029, c-index: 0.6361306743766526\n",
      "    performance on the validation set with penalizer 0.5, l1_ratio 0.8:\n",
      "        stratified c-index: 0.6159481444849957, c-index: 0.6362100600489288\n"
     ]
    }
   ],
   "source": [
    "# naive preprocessor\n",
    "print(\"preformance of the naive preprocessor:\")\n",
    "# performance on the validation set with various penalizer\n",
    "penalizer_list = [0.0, 0.01, 0.2, 0.5]\n",
    "l1_ratio_list = [0.0, 0.2, 0.5, 0.8]\n",
    "tuning_sc_results = -np.ones((4,4))\n",
    "tuning_c_results = -np.ones((4,4))\n",
    "for i, p in enumerate(penalizer_list):\n",
    "    for j, l in enumerate(l1_ratio_list): \n",
    "        print(f\"    performance on the validation set with penalizer {p}, l1_ratio {l}:\")\n",
    "        test_SCIndex, test_C_index = cph_report(df_train, df_val, preproc_naive, penalizer= p, l1_ratio= l)\n",
    "        tuning_sc_results[i][j] = test_SCIndex\n",
    "        tuning_c_results[i][j] = test_C_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        stratified c-index: 0.6399288633895288, c-index: 0.6626878416658459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6399288633895288, np.float64(0.6626878416658459))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performance on the test set\n",
    "cph_report(df_train, df_test, preproc_naive, penalizer= 0.01, l1_ratio= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preformance of the imputing preprocessor:\n",
      "        stratified c-index: 0.6552338517599439, c-index: 0.6732788444905725\n",
      "        stratified c-index: 0.6346773936914096, c-index: 0.6584861584234605\n"
     ]
    }
   ],
   "source": [
    "# designed preprocessor\n",
    "print(\"preformance of the imputing preprocessor:\")\n",
    "# performance on the validation set\n",
    "sc_index, c_index = cph_report(df_train, df_val, preproc, penalizer= 0.01, l1_ratio= 0.2)\n",
    "# performance on the test set\n",
    "sc_index, c_index = cph_report(df_train, df_test, preproc, penalizer= 0.01, l1_ratio= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intereact preprocessor\n",
    "print(\"preformance of the interact preprocessor:\")\n",
    "# performance on the validation set\n",
    "sc_index, c_index = cph_report(df_train, df_val, preproc_interact, penalizer= 0.01, l1_ratio= 0.2)\n",
    "# performance on the test set\n",
    "sc_index, c_index = cph_report(df_train, df_test, preproc_interact, penalizer= 0.01, l1_ratio= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rzhang98\\miniconda3\\envs\\erdo_sp25_post_hct\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dri_score_Intermediate</th>\n",
       "      <th>cyto_score_Poor</th>\n",
       "      <th>cyto_score_missing</th>\n",
       "      <th>graft_type_Peripheral blood</th>\n",
       "      <th>prim_disease_hct_ALL</th>\n",
       "      <th>tce_imm_match_P/P</th>\n",
       "      <th>tce_imm_match_missing</th>\n",
       "      <th>prod_type_PB</th>\n",
       "      <th>cyto_score_detail_Intermediate</th>\n",
       "      <th>cyto_score_detail_missing</th>\n",
       "      <th>...</th>\n",
       "      <th>comorbidity_score karnofsky_score</th>\n",
       "      <th>comorbidity_score hla_low_res_8</th>\n",
       "      <th>comorbidity_score hla_match_drb1_high</th>\n",
       "      <th>comorbidity_score hla_low_res_10</th>\n",
       "      <th>karnofsky_score hla_low_res_8</th>\n",
       "      <th>karnofsky_score hla_match_drb1_high</th>\n",
       "      <th>karnofsky_score hla_low_res_10</th>\n",
       "      <th>hla_low_res_8 hla_match_drb1_high</th>\n",
       "      <th>hla_low_res_8 hla_low_res_10</th>\n",
       "      <th>hla_match_drb1_high hla_low_res_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396712</td>\n",
       "      <td>0.252989</td>\n",
       "      <td>0.336118</td>\n",
       "      <td>-0.005824</td>\n",
       "      <td>-0.146954</td>\n",
       "      <td>-0.195240</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.124508</td>\n",
       "      <td>-0.002158</td>\n",
       "      <td>-0.002866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.195461</td>\n",
       "      <td>0.116394</td>\n",
       "      <td>0.104726</td>\n",
       "      <td>0.125059</td>\n",
       "      <td>-0.812556</td>\n",
       "      <td>-0.731103</td>\n",
       "      <td>-0.873051</td>\n",
       "      <td>0.435360</td>\n",
       "      <td>0.519888</td>\n",
       "      <td>0.467773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557360</td>\n",
       "      <td>0.807646</td>\n",
       "      <td>0.726685</td>\n",
       "      <td>0.867775</td>\n",
       "      <td>0.333917</td>\n",
       "      <td>0.300444</td>\n",
       "      <td>0.358777</td>\n",
       "      <td>0.435360</td>\n",
       "      <td>0.519888</td>\n",
       "      <td>0.467773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396712</td>\n",
       "      <td>-0.574858</td>\n",
       "      <td>-0.517232</td>\n",
       "      <td>-0.617656</td>\n",
       "      <td>0.333917</td>\n",
       "      <td>0.300444</td>\n",
       "      <td>0.358777</td>\n",
       "      <td>0.435360</td>\n",
       "      <td>0.519888</td>\n",
       "      <td>0.467773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057313</td>\n",
       "      <td>-0.574858</td>\n",
       "      <td>-0.517232</td>\n",
       "      <td>-0.617656</td>\n",
       "      <td>-0.048241</td>\n",
       "      <td>-0.043405</td>\n",
       "      <td>-0.051832</td>\n",
       "      <td>0.435360</td>\n",
       "      <td>0.519888</td>\n",
       "      <td>0.467773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 849 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dri_score_Intermediate  cyto_score_Poor  cyto_score_missing  \\\n",
       "0                     1.0              1.0                 0.0   \n",
       "1                     1.0              1.0                 0.0   \n",
       "2                     0.0              0.0                 0.0   \n",
       "3                     0.0              1.0                 0.0   \n",
       "4                     0.0              0.0                 1.0   \n",
       "\n",
       "   graft_type_Peripheral blood  prim_disease_hct_ALL  tce_imm_match_P/P  \\\n",
       "0                          1.0                   0.0                0.0   \n",
       "1                          1.0                   1.0                1.0   \n",
       "2                          1.0                   0.0                1.0   \n",
       "3                          1.0                   1.0                1.0   \n",
       "4                          0.0                   1.0                0.0   \n",
       "\n",
       "   tce_imm_match_missing  prod_type_PB  cyto_score_detail_Intermediate  \\\n",
       "0                    1.0           1.0                             0.0   \n",
       "1                    0.0           1.0                             1.0   \n",
       "2                    0.0           1.0                             1.0   \n",
       "3                    0.0           1.0                             0.0   \n",
       "4                    1.0           0.0                             0.0   \n",
       "\n",
       "   cyto_score_detail_missing  ...  comorbidity_score karnofsky_score  \\\n",
       "0                        0.0  ...                          -0.396712   \n",
       "1                        0.0  ...                          -0.195461   \n",
       "2                        0.0  ...                           0.557360   \n",
       "3                        1.0  ...                          -0.396712   \n",
       "4                        1.0  ...                           0.057313   \n",
       "\n",
       "   comorbidity_score hla_low_res_8  comorbidity_score hla_match_drb1_high  \\\n",
       "0                         0.252989                               0.336118   \n",
       "1                         0.116394                               0.104726   \n",
       "2                         0.807646                               0.726685   \n",
       "3                        -0.574858                              -0.517232   \n",
       "4                        -0.574858                              -0.517232   \n",
       "\n",
       "   comorbidity_score hla_low_res_10  karnofsky_score hla_low_res_8  \\\n",
       "0                         -0.005824                      -0.146954   \n",
       "1                          0.125059                      -0.812556   \n",
       "2                          0.867775                       0.333917   \n",
       "3                         -0.617656                       0.333917   \n",
       "4                         -0.617656                      -0.048241   \n",
       "\n",
       "   karnofsky_score hla_match_drb1_high  karnofsky_score hla_low_res_10  \\\n",
       "0                            -0.195240                        0.003383   \n",
       "1                            -0.731103                       -0.873051   \n",
       "2                             0.300444                        0.358777   \n",
       "3                             0.300444                        0.358777   \n",
       "4                            -0.043405                       -0.051832   \n",
       "\n",
       "   hla_low_res_8 hla_match_drb1_high  hla_low_res_8 hla_low_res_10  \\\n",
       "0                           0.124508                     -0.002158   \n",
       "1                           0.435360                      0.519888   \n",
       "2                           0.435360                      0.519888   \n",
       "3                           0.435360                      0.519888   \n",
       "4                           0.435360                      0.519888   \n",
       "\n",
       "   hla_match_drb1_high hla_low_res_10  \n",
       "0                           -0.002866  \n",
       "1                            0.467773  \n",
       "2                            0.467773  \n",
       "3                            0.467773  \n",
       "4                            0.467773  \n",
       "\n",
       "[5 rows x 849 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_interact.fit(df_train.drop(columns=['efs','efs_time']))\n",
    "X_train_preproc = preproc_interact.transform(df_train.drop(columns=['efs','efs_time']))\n",
    "X_train_preproc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dri_score_Intermediate                 0.230984\n",
       "cyto_score_Poor                        0.212923\n",
       "cyto_score_missing                     0.201069\n",
       "graft_type_Peripheral blood            0.203851\n",
       "prim_disease_hct_ALL                   0.202574\n",
       "                                         ...   \n",
       "karnofsky_score hla_match_drb1_high    1.101140\n",
       "karnofsky_score hla_low_res_10         1.200311\n",
       "hla_low_res_8 hla_match_drb1_high      2.600477\n",
       "hla_low_res_8 hla_low_res_10           2.094742\n",
       "hla_match_drb1_high hla_low_res_10     2.107862\n",
       "Length: 849, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_preproc.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(737)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train_preproc.var() > 0.24).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdo_sp25_post_hct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
